{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from hsi_dataset_api import HsiDataset\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from my_super_attention_net_parts_diff_window_size_opt_change_lr_dyn_new_augs_v9 import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71735d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cut_window = (128, 128)\n",
    "\n",
    "net = MySuperNetLittleInput(17, 17)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    _ = net(torch.randn(1, 17, cut_window[0], cut_window[1]))\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c42b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "w_sorted = sorted(glob.glob('pytorch_li_logs/262391742/*'), \n",
    "       key=lambda x: -float(x.split('/')[-1].split('-')[-1][9:13])\n",
    ")\n",
    "\n",
    "pick_best_one = w_sorted[1]\n",
    "w_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b45dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NnModel.load_from_checkpoint(\n",
    "    pick_best_one, \n",
    "    model=net, loss=nn.CrossEntropyLoss()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1962fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = model.model\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_augmentationv2(image, mask, **kwargs):\n",
    "    image = torch.from_numpy(image)\n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b88000",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_test.npy')\n",
    "# Test\n",
    "dataset_creator_test = DatasetCreator(\n",
    "    PATH_DATA, preprocessing=preprocessing, \n",
    "    indices=test_indices, cut_window=None,\n",
    "    create_shared_memory=False\n",
    ")\n",
    "dataset_test = HsiDataloaderCutter(\n",
    "    images=dataset_creator_test.images, masks=dataset_creator_test.masks,\n",
    "    augmentation=test_augmentationv2,\n",
    "    shuffle_data=False, cut_window=None,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95489dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95988457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_pac_cam(net, x):\n",
    "    x = net.backbone(x)\n",
    "    _, attention_pam = net.pam_module(x, True)\n",
    "    _, attention_cam = net.cam_module(x, True)\n",
    "    return attention_pam, attention_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data_x, val_data = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b612e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_window=(128, 128); image_shape=(512, 512); num_classes=17; divided_batch=4;    \n",
    "batch_size = in_data_x.shape[0]\n",
    "# We will cut image into peases and stack it into single BIG batch\n",
    "h_win, w_win = cut_window\n",
    "h_parts, w_parts = image_shape[1] // w_win, image_shape[0] // h_win\n",
    "in_data_x_parts_list = cut_into_parts_model_input(\n",
    "    in_data_x, h_parts=h_parts, \n",
    "    w_parts=w_parts, h_win=h_win, w_win=w_win\n",
    ")\n",
    "target_parts_list = cut_into_parts_model_input(\n",
    "    val_data.unsqueeze(dim=1), h_parts=h_parts, \n",
    "    w_parts=w_parts, h_win=h_win, w_win=w_win\n",
    ")\n",
    "in_data_x_batch = torch.cat(in_data_x_parts_list, dim=0) # (N, 17, 1, 1)\n",
    "# Make predictions\n",
    "part_divided = len(in_data_x_batch) // divided_batch\n",
    "pred_batch_list = []\n",
    "pred_attention_pam_batch_list = []\n",
    "pred_attention_cam_batch_list = []\n",
    "\n",
    "for b_i in range(part_divided):\n",
    "    if b_i == (part_divided - 1):\n",
    "        # last\n",
    "        single_batch = in_data_x_batch[b_i * divided_batch:]\n",
    "    else:\n",
    "        single_batch = in_data_x_batch[b_i * divided_batch: (b_i+1) * divided_batch]\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        data = single_batch.to(device=device)\n",
    "        preds = net(data).cpu().detach() # (divided_batch, num_classes)\n",
    "        preds_attention_pam, preds_attention_cam  = get_attention_pac_cam(net, data)\n",
    "        preds_attention_pam = preds_attention_pam.cpu().detach()\n",
    "        preds_attention_cam = preds_attention_cam.cpu().detach()\n",
    "\n",
    "    pred_batch_list.append(preds)\n",
    "    pred_attention_pam_batch_list.append(preds_attention_pam)\n",
    "    pred_attention_cam_batch_list.append(preds_attention_cam)\n",
    "\n",
    "preds = torch.cat(pred_batch_list, dim=0)\n",
    "pred_attention_pam = torch.cat(pred_attention_pam_batch_list, dim=0).view(16, 32, 32, 32, 32)\n",
    "pred_attention_cam = torch.cat(pred_attention_cam_batch_list, dim=0).view(16, 128, 128)\n",
    "target = torch.cat(target_parts_list, dim=0)\n",
    "in_data_x_tensor = torch.cat(in_data_x_parts_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5638bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape, target.shape, pred_attention_pam.shape, pred_attention_cam.shape, in_data_x_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = torch.argmax(torch.nn.functional.softmax(preds, dim=1), dim=1)\n",
    "pred_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2450a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h_win, w_win = cut_window\n",
    "h_parts = 512 // h_win\n",
    "w_parts = 512 // w_win\n",
    "\n",
    "\n",
    "def merge_parts_into_single_mask(\n",
    "        preds, shape, h_parts: int, \n",
    "        w_parts: int, h_win: int, w_win: int):\n",
    "    pred_mask = torch.zeros(\n",
    "        shape,\n",
    "        dtype=preds.dtype, device=preds.device\n",
    "    )\n",
    "    counter = 0\n",
    "\n",
    "    for h_i in range(h_parts):\n",
    "        for w_i in range(w_parts):\n",
    "            pred_mask[...,  \n",
    "                h_i * h_win: (h_i+1) * h_win, \n",
    "                w_i * w_win: (w_i+1) * w_win\n",
    "            ] = preds[counter]\n",
    "            counter += 1\n",
    "    return pred_mask\n",
    "\n",
    "pred_big = merge_parts_into_single_mask(\n",
    "    preds, shape=(1, 17, 512, 512), \n",
    "    h_parts=h_parts, w_parts=w_parts, h_win=h_win, w_win=w_win\n",
    ")\n",
    "pred_big_mask = torch.argmax(torch.nn.functional.softmax(pred_big, dim=1), dim=1)\n",
    "target_big_mask = merge_parts_into_single_mask(\n",
    "    target, shape=(1, 512, 512), \n",
    "    h_parts=h_parts, w_parts=w_parts, h_win=h_win, w_win=w_win\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ace30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "sns.heatmap(pred_big_mask[0], vmin=0, vmax=17)\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "sns.heatmap(target_big_mask[0], vmin=0, vmax=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946d3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_b = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pred_mask[indx_b], vmax=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(target[indx_b][0], vmax=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee954ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 2, 2\n",
    "plt.plot(x,y,'bo') \n",
    "sns.heatmap(pred_attention_pam[indx_b][x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6719cc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig_size = 128\n",
    "att_size = 32\n",
    "\n",
    "\n",
    "attention_pam = torch.clone(pred_attention_pam[indx_b])\n",
    "\n",
    "count_x = 4\n",
    "count_y = 4\n",
    "\n",
    "size_x = att_size // count_x\n",
    "size_y = att_size // count_y\n",
    "y_i, x_i = 0, 0\n",
    "mid_x, mid_y = size_x // 2, size_y // 2\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "for i in range(1, count_x * count_y + 1):\n",
    "    fig.add_subplot(count_x, count_y, i)\n",
    "    if x_i == count_x:\n",
    "        x_i = 0\n",
    "        y_i += 1\n",
    "    x, y = mid_x + x_i * size_x, mid_y + y_i * size_y\n",
    "    att_s = attention_pam[y, x].unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "    att_s = torch.nn.functional.interpolate(att_s, (128, 128)).squeeze()\n",
    "    sns.heatmap(att_s)\n",
    "    \n",
    "    x *= (orig_size // att_size)\n",
    "    y *= (orig_size // att_size)\n",
    "    plt.plot(x,y,'bo') \n",
    "    \n",
    "    x_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(in_data_x_tensor[indx_b][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "for i in range(1, 17):\n",
    "    fig.add_subplot(count_x, count_y, i)\n",
    "    sns.heatmap(in_data_x_tensor[indx_b][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data_x = in_data_x_tensor[indx_b]\n",
    "in_data_x_tensor_normed = (s_data_x - s_data_x.min()) / (s_data_x.max() - s_data_x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(in_data_x_tensor_normed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ecc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "for i in range(1, 17):\n",
    "    fig.add_subplot(count_x, count_y, i)\n",
    "    sns.heatmap(in_data_x_tensor_normed[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(torch.sqrt(torch.sum(torch.square(in_data_x_tensor[indx_b]), dim=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(torch.sum(in_data_x_tensor[indx_b], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71942096",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,'bo') \n",
    "sns.heatmap(pred_attention_cam[indx_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b11a045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fa11a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ab3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51db02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42375e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(torch.softmax(preds[indx_b, 5], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515fb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c57b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d19726",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(target_list[indx], vmax=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0912ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(target_list).reshape(-1),\n",
    "    np.asarray(preds_list).reshape(-1), \n",
    "    average='macro'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270ff41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(target_list).reshape(-1),\n",
    "    np.asarray(preds_list).reshape(-1), \n",
    "    average='weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02508b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(target_list).reshape(-1),\n",
    "    np.asarray(preds_list).reshape(-1), \n",
    "    average=None\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
