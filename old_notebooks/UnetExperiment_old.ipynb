{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12720b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60264d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from makitorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import comet_ml\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from makitorch.architectures.U2Net import U2Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsi_dataset_api import HsiDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "from makitorch.architectures.Unet import Unet, UnetWithFeatureSelection\n",
    "from makitorch.loss import muti_bce_loss_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "    iou_score = np.zeros(outputs.shape[1])\n",
    "    outputs[outputs > 0.5] = 1\n",
    "    outputs[outputs <= 0.5] = 0\n",
    "    num_classes = outputs.shape[1]\n",
    "    for _cls in range(num_classes):\n",
    "        output = outputs[::, _cls]\n",
    "        label = torch.clone(labels[::])\n",
    "        label[label != (_cls + 1)] = 0\n",
    "        label[label == (_cls + 1)] = 1\n",
    "        intersection = torch.logical_and(label, output)\n",
    "        union = torch.logical_or(label, output)\n",
    "        iou_score[_cls] = torch.sum(intersection) / (torch.sum(union) + 1e-10)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        if getattr(m, 'bias') is not None:\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f73338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightConstraint(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self,module):\n",
    "        if hasattr(module,'weight'):\n",
    "            w=module.weight.data\n",
    "            w=w.clamp(0, 1)\n",
    "            module.weight.data=w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a84e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, fs_weight, preds, mask):\n",
    "        return self.ce(preds, mask) + torch.sum(1 - (torch.abs(fs_weight) / 0.99 - 1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428abd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NnModel(pl.LightningModule):\n",
    "    def __init__(self, model, loss, enable_image_logging=False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.enable_image_logging = enable_image_logging\n",
    "        self.weight_contraint_function = WeightConstraint()\n",
    "\n",
    "    def _custom_histogram_adder(self):\n",
    "        for name,params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name,params,self.current_epoch)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        img, mask = train_batch\n",
    "        preds = self.model(img)\n",
    "        loss = self.loss(preds, mask)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        img, mask = val_batch\n",
    "        preds = self.model(img)\n",
    "        loss = self.loss(preds, mask)\n",
    "        metric = iou_pytorch(preds, mask)\n",
    "        \n",
    "        if self.enable_image_logging:\n",
    "            pred = torch.argmax(preds.detach().cpu()[0], dim=0)\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "            sns.heatmap(pred, ax=ax1, vmin=0, vmax=17)\n",
    "            sns.heatmap(mask.cpu()[0], ax=ax2, vmin=0, vmax=17)\n",
    "            fig.savefig('temp_fig.png')\n",
    "            plt.close(fig)\n",
    "            \n",
    "#             trainer.logger.experiment.log_histogram_3d(\n",
    "#                 self.model.features_selection.weight.detach().cpu().numpy(),\n",
    "#                 name='band-selection layer',\n",
    "#                 step=self.global_step\n",
    "#             )\n",
    "            if hasattr(trainer.logger.experiment, 'log_image'):\n",
    "                # For Comet logger\n",
    "                trainer.logger.experiment.log_image('temp_fig.png', name=f'{batch_idx}', overwrite=False, step=self.global_step)\n",
    "            else:\n",
    "                # For tensorboard logger\n",
    "                img = cv2.imread('temp_fig.png')\n",
    "                trainer.logger.experiment.add_image(f'{batch_idx}', img, dataformats='HWC')\n",
    "        \n",
    "        d = {f'iou_{i}': iou for i, iou in enumerate(metric)}\n",
    "        d['val_loss'] = loss\n",
    "        self.log_dict(d, on_step=False, on_epoch=True, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d86dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_explained_variance = np.load('PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load('PcaMean.npy')\n",
    "pca_components = np.load('PcaComponents.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b4acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transformation(x):\n",
    "    x_t = np.reshape(x, (x.shape[0], -1)) # (C, H, W) -> (C, H * W)\n",
    "    x_t = np.swapaxes(x_t, 0, 1) # (C, H * W) -> (H * W, C)\n",
    "    x_t = x_t - pca_mean\n",
    "    x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "    return np.reshape(x_t, (x.shape[1], x.shape[2], pca_components.shape[0])).astype(np.float32) # (H, W, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(imgs, masks):\n",
    "    target_size = (256, 256)\n",
    "    _images = [image.resize(target_size,Image.BILINEAR)\n",
    "                   for image in imgs]\n",
    "    _masks = [mask.resize(target_size, Image.BILINEAR) for mask in masks]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55211d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(imgs, masks):\n",
    "    with open('data_standartization_params.json', 'r') as f:\n",
    "        data_standartization_params = json.load(f)\n",
    "    mean = data_standartization_params.get('means')\n",
    "    std = data_standartization_params.get('stds')\n",
    "    def standartization(img):\n",
    "        return np.array((img - mean) / std, dtype=np.float32)\n",
    "    \n",
    "    _images = [pca_transformation(image) for image in imgs]\n",
    "    _images = [standartization(image) for image in _images]\n",
    "    _masks = [np.expand_dims(cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY).astype(np.int64), 0) for mask in masks]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69079a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_augmentation(image, mask):\n",
    "    image = TF.to_tensor(image)\n",
    "    mask = torch.from_numpy(mask)\n",
    "    \n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16432260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(image, mask):\n",
    "    image = TF.to_tensor(image)\n",
    "    mask = torch.from_numpy(mask)\n",
    "    \n",
    "    angle = T.RandomRotation.get_params((-30, 30))\n",
    "    image = TF.rotate(image, angle, interpolation=T.InterpolationMode.BILINEAR)\n",
    "    mask = TF.rotate(mask, angle, interpolation=T.InterpolationMode.NEAREST)\n",
    "    \n",
    "    if np.random.random() > 0.5:\n",
    "        image = TF.hflip(image)\n",
    "        mask = TF.hflip(mask)\n",
    "\n",
    "    if np.random.random() > 0.5:\n",
    "        image = TF.vflip(image)\n",
    "        mask = TF.vflip(mask)\n",
    "    \n",
    "#     image = (image - image.min()) / (image.max() - image.min())\n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf4601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random = np.random.permutation(np.arange(384))\n",
    "# test_indices = random[310:]\n",
    "# train_indices = random[:310]\n",
    "\n",
    "test_indices = np.load('test_indices.npy')\n",
    "train_indices = np.load('train_indices.npy')\n",
    "path = '/raid/rustam/hyperspectral_dataset/cropped_hsi_data'\n",
    "\n",
    "dataset_train = HsiDataloader(path, preprocessing=preprocessing, augmentation=augmentation, indices=train_indices)\n",
    "dataset_test = HsiDataloader(path, preprocessing=preprocessing, augmentation=test_augmentation, indices=test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = next(iter(val_loader))[1]\n",
    "mask = torch.unsqueeze(mask, axis=0)\n",
    "mask.shape, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(outputs - labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce94c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e22256",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = next(iter(val_loader))[1]\n",
    "output = output.type(torch.float)\n",
    "outputs = torch.unsqueeze(outputs, axis=0)\n",
    "print(outputs.shape)\n",
    "\n",
    "labels = torch.clone(outputs)\n",
    "print(labels.shape)\n",
    "# You can comment out this line if you are passing tensors of equal shape\n",
    "# But if you are passing output from UNet or something it will most probably\n",
    "# be with the BATCH x 1 x H x W shape\n",
    "#outputs = torch.sigmoid(outputs)\n",
    "iou_score = np.zeros(outputs.shape[1])\n",
    "outputs[outputs > 0.5] = 1\n",
    "outputs[outputs <= 0.5] = 0\n",
    "num_classes = outputs.shape[1]\n",
    "for _cls in range(num_classes):\n",
    "    output = outputs[::, _cls]\n",
    "    label = torch.clone(labels[::])\n",
    "    label[label != (_cls + 1)] = 0\n",
    "    label[label == (_cls + 1)] = 1\n",
    "    intersection = torch.logical_and(label, output)\n",
    "    union = torch.logical_or(label, output)\n",
    "    iou_score[_cls] = torch.sum(intersection) / (torch.sum(union) + 1e-10)\n",
    "print(iou_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4baf034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTroch version\n",
    "\n",
    "SMOOTH = 1e-6\n",
    "\n",
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    \n",
    "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    \n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean() if you are interested in average across the batch\n",
    "    \n",
    "    \n",
    "# Numpy version\n",
    "# Well, it's the same function, so I'm going to omit the comments\n",
    "\n",
    "def iou_numpy(outputs: np.array, labels: np.array):\n",
    "    outputs = outputs.squeeze(1)\n",
    "    \n",
    "    intersection = (outputs & labels).sum((1, 2))\n",
    "    union = (outputs | labels).sum((1, 2))\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    \n",
    "    thresholded = np.ceil(np.clip(20 * (iou - 0.5), 0, 10)) / 10\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ae719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b405b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6664dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Unet(in_channels=17, out_channels=17, init_features=128, pretrained=False)\n",
    "# net = net.apply(init_weights)\n",
    "    # net = UnetWithFeatureSelection(in_channels=236, out_channels=17, init_features=128, pretrained=False)\n",
    "\n",
    "# net = U2Net(17, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_val = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data_x, target = next(iter_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = net(in_data_x)\n",
    "logit.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6630c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = logit.shape[1]\n",
    "num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "if logit.dim() > 2:\n",
    "    print(logit.shape)\n",
    "    # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "    logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "    logit = logit.permute(0, 2, 1).contiguous()\n",
    "    logit = logit.view(-1, logit.size(-1))\n",
    "    print('reshape')\n",
    "    print(logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.squeeze(target, 1)\n",
    "target = target.view(-1, 1)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df69a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = torch.ones(num_class, 1)\n",
    "if alpha.device != logit.device:\n",
    "    alpha = alpha.to(logit.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68aa40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = target.cpu().long()\n",
    "idx.shape, idx[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_key = torch.FloatTensor(target.size(0), num_class).zero_()\n",
    "one_hot_key = one_hot_key.scatter_(1, idx, 1)\n",
    "\n",
    "if one_hot_key.device != logit.device:\n",
    "    one_hot_key = one_hot_key.to(logit.device)\n",
    "\n",
    "one_hot_key.shape, one_hot_key[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1e-3\n",
    "if smooth:\n",
    "    one_hot_key = torch.clamp(\n",
    "        one_hot_key, smooth/(num_class-1), 1.0 - smooth\n",
    "    )\n",
    "one_hot_key.shape, one_hot_key[-1], logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aff5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = (one_hot_key * logit).sum(1) + smooth\n",
    "pt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logpt = pt.log()\n",
    "logpt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 4\n",
    "\n",
    "alpha = alpha[idx]\n",
    "alpha = torch.squeeze(alpha)\n",
    "loss = -1 * alpha * torch.pow((1 - pt), gamma) * logpt\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cda9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28389825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norm by positive\n",
    "num_positive = torch.sum((target != 0))\n",
    "loss.sum() / (num_positive + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63743474",
   "metadata": {},
   "outputs": [],
   "source": [
    "cel = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6456fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = cel(logit, target.view(-1))\n",
    "ce_loss, ce_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8669f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 2\n",
    "num_class = logit.shape[1]\n",
    "cel = nn.CrossEntropyLoss(reduction='none')\n",
    "if logit.dim() > 2:\n",
    "    # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "    logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "    logit = logit.permute(0, 2, 1).contiguous()\n",
    "    logit = logit.view(-1, logit.size(-1))\n",
    "target = torch.squeeze(target, 1)\n",
    "target = target.view(-1, 1)\n",
    "\n",
    "ce_loss = cel(logit, target.view(-1))\n",
    "train_conf = nn.Softmax(dim=-1)(logit)\n",
    "idx = target.cpu().long()\n",
    "one_hot_labels  = torch.FloatTensor(target.size(0), num_class).zero_()\n",
    "one_hot_labels  = one_hot_labels.scatter_(1, idx, 1)\n",
    "if one_hot_labels.device != logit.device:\n",
    "    one_hot_labels = one_hot_labels.to(logit.device)\n",
    "\n",
    "filtered_conf = train_conf * one_hot_labels\n",
    "sparce_conf, _ = torch.max(filtered_conf, dim=-1)\n",
    "focal_w = torch.pow((torch.ones_like(sparce_conf) - sparce_conf), gamma) * ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_w.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_positive = torch.sum(target != 2)\n",
    "focal_w.sum() / (num_positive + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40639e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7d7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CometLogger(\n",
    "    api_key=\"your-key\",\n",
    "    workspace=\"your-workspace\",  # Optional\n",
    "    project_name=\"your-project-name\",  # Optional\n",
    "    experiment_name=\"New run\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NnModel(net, muti_bce_loss_fusion, enable_image_logging=True)\n",
    "model = NnModel(net, FocalLoss(), enable_image_logging=True)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, \n",
    "    max_epochs=6,\n",
    "    check_val_every_n_epoch=2,\n",
    "    logger=logger\n",
    ")\n",
    "# trainer = pl.Trainer(\n",
    "#     gpus=1, \n",
    "#     max_epochs=2000,\n",
    "#     check_val_every_n_epoch=2000)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e3e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.experiment.log_html(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ed428",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(net.features_selection.weight.detach().cpu().numpy()[::, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.zeros((17, ))\n",
    "std = np.zeros((17, ))\n",
    "count = 0\n",
    "for img, mask in train_loader:\n",
    "    img = img.detach().cpu().numpy()\n",
    "    mean += img.mean(axis=(2, 3))[0]\n",
    "    std += img.std(axis=(2, 3))[0]\n",
    "    count += 1\n",
    "mean /= count\n",
    "std /= count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f238004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data_standartization_params.json', 'w') as f:\n",
    "#     json.dump(\n",
    "#         {\n",
    "#             \"means\": mean.tolist(),\n",
    "#             \"stds\": std.tolist()\n",
    "#         }, f\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f38d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(itertools.islice(train_loader.__iter__(), 0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = net.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923fda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(17, 1, figsize=(6, 30))\n",
    "for i, ax in enumerate(axis):\n",
    "    sns.heatmap(preds[i], ax=ax, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ba81c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
