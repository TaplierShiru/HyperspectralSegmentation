{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from hsi_dataset_api import HsiDataset\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_INFO_PATH = '/home/rustam/hyperspecter_segmentation/danil_cave/kfolds_data/kfold0'\n",
    "PATH_DATA = '/raid/rustam/hyperspectral_dataset/new_cropped_hsi_data'\n",
    "\n",
    "\n",
    "pca_explained_variance = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaMean.npy')\n",
    "pca_components = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaComponents.npy')\n",
    "\n",
    "\n",
    "test_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_test.npy')\n",
    "train_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_train.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transformation(x):\n",
    "    x_t = np.reshape(x, (x.shape[0], -1)) # (C, H, W) -> (C, H * W)\n",
    "    x_t = np.swapaxes(x_t, 0, 1) # (C, H * W) -> (H * W, C)\n",
    "    x_t = x_t - pca_mean\n",
    "    x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "    return np.reshape(x_t, (x.shape[1], x.shape[2], pca_components.shape[0])).astype(np.float32) # (H, W, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_augmentation(image, mask):\n",
    "    image = TF.to_tensor(image)\n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    \n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def preprocessing(imgs, masks):\n",
    "    with open(f'{PREFIX_INFO_PATH}/data_standartization_params_kfold0.json', 'r') as f:\n",
    "        data_standartization_params = json.load(f)\n",
    "    mean = data_standartization_params.get('means')\n",
    "    std = data_standartization_params.get('stds')\n",
    "    assert mean is not None and std is not None\n",
    "    def standartization(img):\n",
    "        return np.array((img - mean) / std, dtype=np.float32)\n",
    "    _images = [np.transpose(image, (1, 2, 0)) for image in imgs] #[pca_transformation(image) for image in imgs]\n",
    "    #_images = [standartization(image) for image in _images]\n",
    "    _masks = [\n",
    "        np.expand_dims(\n",
    "            cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "            ,0\n",
    "        ).astype(np.int64)\n",
    "        for mask in masks\n",
    "    ]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = HsiDataloader(\n",
    "    PATH_DATA, preprocessing=preprocessing, \n",
    "    augmentation=test_augmentation, indices=test_indices\n",
    ")\n",
    "\n",
    "dataset_train = HsiDataloader(\n",
    "    PATH_DATA, preprocessing=preprocessing,\n",
    "    augmentation=test_augmentation, indices=train_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c16620",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, num_workers=10)\n",
    "\n",
    "val_loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390daea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f101f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_loader = val_loader_train\n",
    "\n",
    "specter_list = []\n",
    "target_list = []\n",
    "\n",
    "for img_s, mask_s in tqdm(val_loader):\n",
    "    specter_list.append(img_s[0].numpy())\n",
    "    target_list.append(mask_s[0].numpy())\n",
    "len(specter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdf68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 6\n",
    "indx_sp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(specter_list[indx][indx_sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d19726",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(target_list[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = specter_list[indx][:, :32, :32].copy().reshape(-1)\n",
    "sns.distplot(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08588477",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = specter_list[indx][indx_sp].copy().reshape(-1)\n",
    "sns.distplot(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((specter_list[indx][indx_sp] * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae810ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca7dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee413b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ff327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_test = dict([(str(i), 0) for i in range(17)])\n",
    "num_class2count_train = dict([(str(i), 0) for i in range(17)])\n",
    "\n",
    "num_class2count_pixels_test = dict([(str(i), 0) for i in range(17)])\n",
    "num_class2count_pixels_train = dict([(str(i), 0) for i in range(17)])\n",
    "\n",
    "# Test count\n",
    "for img_s, mask_s in tqdm(val_loader_test):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_test[str(n_c)] += 1\n",
    "\n",
    "# Train count\n",
    "for img_s, mask_s in tqdm(val_loader_train):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_train[str(n_c)] += 1\n",
    "\n",
    "# Test pixels\n",
    "for img_s, mask_s in tqdm(val_loader_test):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_pixels_test[str(n_c)] += torch.sum(mask_s == n_c).numpy()\n",
    "\n",
    "# Train pixels\n",
    "for img_s, mask_s in tqdm(val_loader_train):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_pixels_train[str(n_c)] += torch.sum(mask_s == n_c).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3800c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_train, index=[0]) / 324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04232aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_test, index=[0]) / 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_diff = dict()\n",
    "\n",
    "for k,v in num_class2count_test.items():\n",
    "    num_class2count_diff[str(k)] = v - num_class2count_train[k]\n",
    "    print(f'class={str(k).zfill(2)} num_test={str(v).zfill(2)} num_train={str(num_class2count_train[k]).zfill(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_diff, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_train, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_test, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_pixels_diff = dict()\n",
    "\n",
    "for k,v in num_class2count_pixels_test.items():\n",
    "    num_class2count_pixels_diff[str(k)] = v - num_class2count_pixels_train[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d75b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_diff, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8179b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
