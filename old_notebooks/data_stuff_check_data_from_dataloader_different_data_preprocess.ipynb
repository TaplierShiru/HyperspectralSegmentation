{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "GPU_ID = \"0\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "\n",
    "PREFIX_INFO_PATH = '/home/rustam/hyperspecter_segmentation/danil_cave/kfolds_data/kfold0'\n",
    "PATH_DATA = '/raid/rustam/hyperspectral_dataset/new_cropped_hsi_data'\n",
    "\n",
    "\n",
    "from multiprocessing.dummy import Pool\n",
    "from multiprocessing import shared_memory\n",
    "import copy\n",
    "from makitorch import *\n",
    "import math\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import comet_ml\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from makitorch.architectures.U2Net import U2Net\n",
    "\n",
    "from hsi_dataset_api import HsiDataset\n",
    "\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "from makitorch.architectures.Unet import Unet, UnetWithFeatureSelection\n",
    "from makitorch.loss import muti_bce_loss_fusion\n",
    "from sklearn.metrics import jaccard_score\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "from makitorch.data_tools.augmentation import DataAugmentator\n",
    "from makitorch.data_tools.augmentation import BaseDataAugmentor\n",
    "from makitorch.data_tools.preprocessing import BaseDataPreprocessor\n",
    "from makitorch.data_tools.preprocessing import DataPreprocessor\n",
    "\n",
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "from hsi_dataset_api import HsiDataset\n",
    "\n",
    "\n",
    "@nb.njit\n",
    "def cut_into_parts(\n",
    "        image: np.ndarray, mask: np.ndarray, h_parts: int, \n",
    "        w_parts: int, h_win: int, w_win: int):\n",
    "    image_parts_list = []\n",
    "    mask_parts_list = []\n",
    "\n",
    "    for h_i in range(h_parts):\n",
    "        for w_i in range(w_parts):\n",
    "            img_part = image[:, \n",
    "                h_i * h_win: (h_i+1) * h_win, \n",
    "                w_i * w_win: (w_i+1) * w_win\n",
    "            ]\n",
    "            mask_part = mask[\n",
    "                h_i * h_win: (h_i+1) * h_win, \n",
    "                w_i * w_win: (w_i+1) * w_win\n",
    "            ]\n",
    "\n",
    "            image_parts_list.append(img_part)\n",
    "            mask_parts_list.append(mask_part)\n",
    "    return image_parts_list, mask_parts_list\n",
    "\n",
    "\n",
    "class ShmData:\n",
    "\n",
    "    def __init__(self, shm_name, shape, dtype):\n",
    "        self.shm_name = shm_name\n",
    "        self.shape = shape\n",
    "        self.dtype = dtype\n",
    "\n",
    "\n",
    "class DatasetCreator:\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            data_path: str,\n",
    "            preprocessing: Optional[Union[DataPreprocessor, Callable]] = BaseDataPreprocessor(),\n",
    "            indices = None,\n",
    "            cut_window=(8, 8),\n",
    "            map_mask_to_class=False,\n",
    "            create_shared_memory=False,\n",
    "            shuffle_then_prepared=False):\n",
    "        self.dataset = HsiDataset(data_path)\n",
    "        self.preprocessing = preprocessing\n",
    "        self.cut_window = cut_window\n",
    "        self.map_mask_to_class = map_mask_to_class\n",
    "        self.create_shared_memory = create_shared_memory\n",
    "        \n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        self._shm_imgs = None\n",
    "        self._shm_masks = None\n",
    "\n",
    "        for idx, data_point in tqdm(enumerate(self.dataset.data_iterator(opened=True, shuffle=False))):\n",
    "            if indices is not None and idx not in indices:\n",
    "                continue\n",
    "            image, mask = data_point.hsi, data_point.mask\n",
    "            if cut_window is not None:\n",
    "                image_parts, mask_parts = self._cut_with_window(image, mask, cut_window)\n",
    "                self.images += image_parts\n",
    "                self.masks += mask_parts\n",
    "            else:\n",
    "                self.images.append(image)\n",
    "                self.masks.append(mask)\n",
    "        print(\"Preprocess data...\")\n",
    "        if self.preprocessing is not None:\n",
    "            self.images, self.masks = self.preprocessing(\n",
    "                self.images, self.masks, map_mask_to_class=map_mask_to_class\n",
    "            )\n",
    "\n",
    "        if shuffle_then_prepared:\n",
    "            self.images, self.masks = shuffle(self.images, self.masks)\n",
    "\n",
    "        # Create shared memory\n",
    "        if create_shared_memory:\n",
    "            print('Create shared memory...')\n",
    "            # First - map images and masks into np\n",
    "            self.images = np.asarray(self.images, dtype=np.float32)\n",
    "            self.masks = np.asarray(self.masks, dtype=np.int64)\n",
    "            # Imgs\n",
    "            shm_imgs = shared_memory.SharedMemory(create=True, size=self.images.nbytes)\n",
    "            shm_imgs_arr = np.ndarray(self.images.shape, dtype=self.images.dtype, buffer=shm_imgs.buf)\n",
    "            shm_imgs_arr[:] = self.images[:]\n",
    "            self.images = shm_imgs_arr # Do not keep dublicate \n",
    "            self.data_shm_imgs = ShmData(\n",
    "                shm_name=shm_imgs.name, shape=self.images.shape, \n",
    "                dtype=self.images.dtype\n",
    "            )\n",
    "            self._shm_imgs = shm_imgs\n",
    "            # Masks\n",
    "            shm_masks = shared_memory.SharedMemory(create=True, size=self.masks.nbytes)\n",
    "            shm_masks_arr = np.ndarray(self.masks.shape, dtype=self.masks.dtype, buffer=shm_masks.buf)\n",
    "            shm_masks_arr[:] = self.masks[:]\n",
    "            self.masks = shm_masks_arr # Do not keep dublicate \n",
    "            self.data_shm_masks = ShmData(\n",
    "                shm_name=shm_masks.name, shape=self.masks.shape,\n",
    "                dtype=self.masks.dtype\n",
    "            )\n",
    "            self._shm_masks = shm_masks\n",
    "            print(\"Shared memory are created for imgs and masks!\")\n",
    "\n",
    "    def close_shm(self):\n",
    "        if self.create_shared_memory:\n",
    "            # Make sure there is no reference data to images/masks\n",
    "            del self.images\n",
    "            del self.masks\n",
    "            self.images = []\n",
    "            self.masks = []\n",
    "            # Close and unlink\n",
    "            if self._shm_masks is not None:\n",
    "                self._shm_masks.close()\n",
    "                self._shm_masks.unlink()\n",
    "                self._shm_masks = None\n",
    "\n",
    "            if self._shm_imgs is not None:\n",
    "                self._shm_imgs.close()\n",
    "                self._shm_imgs.unlink()\n",
    "                self._shm_imgs = None\n",
    "            print(\"Shared memory for masks and images are success cleared!\")\n",
    "                    \n",
    "    \n",
    "    def _cut_with_window(self, image, mask, cut_window):\n",
    "        assert len(cut_window) == 2\n",
    "        h_win, w_win = cut_window\n",
    "        _, h, w = image.shape\n",
    "        h_parts = h // h_win\n",
    "        w_parts = w // w_win\n",
    "        if h % h_win != 0:\n",
    "            print(f\"{h % h_win} pixels will be dropped by h axis. Input shape={image.shape}\")\n",
    "\n",
    "        if w % w_win != 0:\n",
    "            print(f\"{w % w_win} pixels will be dropped by w axis. Input shape={image.shape}\")\n",
    "        return cut_into_parts(\n",
    "            image=image, mask=mask, h_parts=h_parts, w_parts=w_parts,\n",
    "            h_win=h_win, w_win=w_win\n",
    "        )\n",
    "\n",
    "\n",
    "class HsiDataloaderCutter(torch.utils.data.IterableDataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            images, masks,\n",
    "            augmentation: Optional[Union[DataAugmentator, Callable]] = BaseDataAugmentor(),\n",
    "            shuffle_data=False,\n",
    "            cut_window=(8, 8),\n",
    "            map_mask_to_class=False,\n",
    "            shared_memory_imgs_data: ShmData = None,\n",
    "            shared_memory_masks_data: ShmData = None\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.shuffle_data = shuffle_data\n",
    "        self.augmentation = augmentation\n",
    "        if cut_window is not None and cut_window[0] == 1 and cut_window[1] == 1:\n",
    "            self.ignore_image_augs = True\n",
    "        else:\n",
    "            self.ignore_image_augs = False\n",
    "        self.cut_window = cut_window\n",
    "        self.map_mask_to_class = map_mask_to_class\n",
    "        self.shared_memory_imgs_data = shared_memory_imgs_data\n",
    "        self.shared_memory_masks_data = shared_memory_masks_data\n",
    "        \n",
    "        self.shm_imgs: shared_memory.SharedMemory = None\n",
    "        self.shm_masks: shared_memory.SharedMemory = None\n",
    "\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "\n",
    "    def __iter__(self):\n",
    "        assert self.images is not None and self.masks is not None\n",
    "        if self.shuffle_data:\n",
    "            self.images, self.masks = shuffle(self.images, self.masks)\n",
    "        \n",
    "        for image, mask in zip(self.images, self.masks):\n",
    "            yield self.augmentation(\n",
    "                image, mask, \n",
    "                map_mask_to_class=self.map_mask_to_class,\n",
    "                ignore_image_augs=self.ignore_image_augs\n",
    "            )\n",
    "\n",
    "\n",
    "def pca_transformation(x):\n",
    "    if len(x.shape) == 3:\n",
    "        x_t = x.reshape((x.shape[0], -1)) # (C, H, W) -> (C, H * W)\n",
    "        x_t = np.transpose(x_t, (1, 0)) # (C, H * W) -> (H * W, C)\n",
    "        x_t = x_t - pca_mean\n",
    "        x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "        return x_t.reshape((x.shape[1], x.shape[2], pca_components.shape[0])).astype(np.float32, copy=False) # (H, W, N)\n",
    "    elif len(x.shape) == 4:\n",
    "        # x - (N, C, H, W)\n",
    "        x_t = np.transpose(x, (0, 2, 3, 1)) # (N, C, H, W) -> (N, H, W, C)\n",
    "        x_t = x_t - pca_mean\n",
    "        x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "        x_t = np.transpose(x_t, (0, -1, 1, 2)) # (N, H, W, C) -> (N, C, H, W)\n",
    "        return x_t.astype(np.float32, copy=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown shape={x.shape}, must be of len 3 or 4.\")\n",
    "\n",
    "def standartization(img, mean, std):\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    return img\n",
    "\n",
    "def standartization_pool(mean, std):\n",
    "    # X shape - (N, C, H, W)\n",
    "    # from shape (comp,) -> (1, comp, 1, 1)\n",
    "    mean = np.expand_dims(np.expand_dims(np.array(mean, dtype=np.float32), axis=-1), axis=-1)\n",
    "    std = np.expand_dims(np.expand_dims(np.array(std, dtype=np.float32), axis=-1), axis=-1)\n",
    "    \n",
    "    return lambda x: standartization(x, mean=mean, std=std)\n",
    "\n",
    "\n",
    "def mask2class(mask):\n",
    "    # Calculate which class have more pixel count\n",
    "    max_value = -1\n",
    "    pixel_count = -1\n",
    "    for class_indx in np.unique(mask):\n",
    "        pix_count_s = np.sum(mask == class_indx)\n",
    "        if pix_count_s > pixel_count:\n",
    "            max_value = class_indx\n",
    "            pixel_count = pix_count_s\n",
    "    assert max_value != -1\n",
    "    return np.array([max_value], dtype=np.int64) \n",
    "\n",
    "\n",
    "def preprocessing(imgs, masks, map_mask_to_class=False, split_size=256):\n",
    "    with open(f'{PREFIX_INFO_PATH}/data_standartization_params_kfold0.json', 'r') as f:\n",
    "        data_standartization_params = json.load(f)\n",
    "    mean = data_standartization_params.get('means')\n",
    "    std = data_standartization_params.get('stds')\n",
    "    assert mean is not None and std is not None\n",
    "    print('Create np array of imgs and masks...')\n",
    "    imgs_np = np.asarray(imgs, dtype=np.float32) # (N, 237, 1, 1)\n",
    "    masks_np = np.asarray(masks, dtype=np.int64) # (N, 1, 1, 3)\n",
    "    print(\"Split imgs dataset...\")\n",
    "    imgs_split_np = np.array_split(imgs_np, split_size) # (split_size, Ns, 237, 1, 1)\n",
    "    print('Start preprocess images...')\n",
    "    # Wo PCA\n",
    "    # _images = [np.transpose(image, (1, 2, 0)) for image in imgs]\n",
    "    # W Pca\n",
    "    with Pool(18) as p:\n",
    "        _images = list(tqdm(p.imap(\n",
    "                pca_transformation, \n",
    "                imgs_split_np,\n",
    "                #chunksize=1\n",
    "            ), total=len(imgs_split_np))\n",
    "        )\n",
    "        _images = list(tqdm(p.imap(\n",
    "            standartization_pool(mean=mean, std=std), \n",
    "            _images,\n",
    "            #chunksize=1\n",
    "            ), total=len(imgs_split_np))\n",
    "        )\n",
    "    _images = list(np.concatenate(_images, axis=0)) # (split_size, Ns, 237, 1, 1) -> (split_size * Ns, 237, 1, 1)\n",
    "    print(\"Preprocess masks...\")\n",
    "    _masks = list(np.transpose(masks_np[..., 0:1], (0, -1, 1, 2)))\n",
    "    print(\"Finish preprocess!\")\n",
    "    if map_mask_to_class:\n",
    "        _masks = [mask2class(mask) for mask in _masks]\n",
    "    return _images, _masks\n",
    "\n",
    "\n",
    "def test_augmentation(image, mask, **kwargs):\n",
    "    image = torch.from_numpy(image)\n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def augmentation(image, mask, map_mask_to_class=False, ignore_image_augs=False):\n",
    "    image = torch.from_numpy(image)\n",
    "    mask = torch.from_numpy(mask)\n",
    "    if not ignore_image_augs:\n",
    "        # Rotate\n",
    "        angle = T.RandomRotation.get_params((-30, 30))\n",
    "        image = TF.rotate(image, angle, interpolation=T.InterpolationMode.BILINEAR)\n",
    "        if not map_mask_to_class:\n",
    "            mask = TF.rotate(mask, angle, interpolation=T.InterpolationMode.NEAREST)\n",
    "        # Flip horizontal\n",
    "        if torch.rand(1) > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            if not map_mask_to_class:\n",
    "                mask = TF.hflip(mask)\n",
    "        # Flip vertical\n",
    "        if torch.rand(1) > 0.5:\n",
    "            image = TF.vflip(image)\n",
    "            if not map_mask_to_class:\n",
    "                mask = TF.vflip(mask)\n",
    "    \n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_INFO_PATH = '/home/rustam/hyperspecter_segmentation/danil_cave/kfolds_data/kfold0'\n",
    "PATH_DATA = '/raid/rustam/hyperspectral_dataset/new_cropped_hsi_data'\n",
    "\n",
    "\n",
    "pca_explained_variance = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaMean.npy')\n",
    "pca_components = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaComponents.npy')\n",
    "\n",
    "\n",
    "test_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_test.npy')\n",
    "train_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_train.npy')\n",
    "\n",
    "cut_window = (512, 512)\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313bb92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_creator_train = DatasetCreator(\n",
    "    PATH_DATA, preprocessing=preprocessing, \n",
    "    indices=train_indices, cut_window=cut_window,\n",
    "    create_shared_memory=False, shuffle_then_prepared=True\n",
    ")\n",
    "dataset_train = HsiDataloaderCutter(\n",
    "    images=dataset_creator_train.images, masks=dataset_creator_train.masks,\n",
    "    augmentation=augmentation,\n",
    "    shuffle_data=True, cut_window=cut_window,\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=batch_size, drop_last=True\n",
    ")\n",
    "# Test\n",
    "dataset_creator_test = DatasetCreator(\n",
    "    PATH_DATA, preprocessing=preprocessing, \n",
    "    indices=test_indices, cut_window=None,\n",
    "    create_shared_memory=False\n",
    ")\n",
    "dataset_test = HsiDataloaderCutter(\n",
    "    images=dataset_creator_test.images, masks=dataset_creator_test.masks,\n",
    "    augmentation=test_augmentation,\n",
    "    shuffle_data=False, cut_window=None,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390daea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f101f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_loader = train_loader\n",
    "\n",
    "specter_list = []\n",
    "target_list = []\n",
    "\n",
    "for img_s, mask_s in tqdm(val_loader):\n",
    "    specter_list.append(img_s.numpy())\n",
    "    target_list.append(mask_s.numpy())\n",
    "len(specter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdf68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_b = 0\n",
    "indx = 122\n",
    "indx_sp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(specter_list[indx][indx_b][indx_sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d19726",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(target_list[indx][indx_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = specter_list[indx][indx_b][:, :32, :32].copy().reshape(-1)\n",
    "sns.distplot(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb694a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = specter_list[indx][indx_b][indx_sp].copy().reshape(-1)\n",
    "sns.distplot(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((specter_list[indx][indx_b][indx_sp] * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a519b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cube = specter_list[indx][indx_b][indx_sp].copy().reshape(-1)\n",
    "cube = (cube * 255).astype(np.uint8)\n",
    "cube = cv2.equalizeHist(cube)\n",
    "cube = (cube / 255).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944568f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((cube.reshape(512, 512) * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113f0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1213480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cube = specter_list[indx][indx_b][indx_sp].copy().reshape(-1)\n",
    "cube = (cube * 255).astype(np.uint8)\n",
    "# create a CLAHE object (Arguments are optional).\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "cube = clahe.apply(cube)\n",
    "cube = (cube / 255).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48fa379",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90472fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((cube.reshape(512, 512) * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8959645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a266239f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143a773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203cea1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ff327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_test = dict([(str(i), 0) for i in range(17)])\n",
    "num_class2count_train = dict([(str(i), 0) for i in range(17)])\n",
    "\n",
    "num_class2count_pixels_test = dict([(str(i), 0) for i in range(17)])\n",
    "num_class2count_pixels_train = dict([(str(i), 0) for i in range(17)])\n",
    "\n",
    "# Test count\n",
    "for img_s, mask_s in tqdm(val_loader_test):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_test[str(n_c)] += 1\n",
    "\n",
    "# Train count\n",
    "for img_s, mask_s in tqdm(val_loader_train):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_train[str(n_c)] += 1\n",
    "\n",
    "# Test pixels\n",
    "for img_s, mask_s in tqdm(val_loader_test):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_pixels_test[str(n_c)] += torch.sum(mask_s == n_c).numpy()\n",
    "\n",
    "# Train pixels\n",
    "for img_s, mask_s in tqdm(val_loader_train):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_pixels_train[str(n_c)] += torch.sum(mask_s == n_c).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3800c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_train, index=[0]) / 324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04232aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_test, index=[0]) / 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_diff = dict()\n",
    "\n",
    "for k,v in num_class2count_test.items():\n",
    "    num_class2count_diff[str(k)] = v - num_class2count_train[k]\n",
    "    print(f'class={str(k).zfill(2)} num_test={str(v).zfill(2)} num_train={str(num_class2count_train[k]).zfill(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_diff, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_train, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_test, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_pixels_diff = dict()\n",
    "\n",
    "for k,v in num_class2count_pixels_test.items():\n",
    "    num_class2count_pixels_diff[str(k)] = v - num_class2count_pixels_train[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d75b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_diff, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8179b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
