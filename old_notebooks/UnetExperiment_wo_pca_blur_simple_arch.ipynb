{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12720b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60264d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from makitorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import comet_ml\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from makitorch.architectures.U2Net import U2Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsi_dataset_api import HsiDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "from makitorch.architectures.Unet import Unet, UnetWithFeatureSelection\n",
    "from makitorch.loss import muti_bce_loss_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "    iou_score = np.zeros(outputs.shape[1])\n",
    "    outputs[outputs > 0.5] = 1\n",
    "    outputs[outputs <= 0.5] = 0\n",
    "    num_classes = outputs.shape[1]\n",
    "    for _cls in range(num_classes):\n",
    "        output = outputs[::, _cls]\n",
    "        label = torch.clone(labels[::])\n",
    "        label[label != (_cls + 1)] = 0\n",
    "        label[label == (_cls + 1)] = 1\n",
    "        intersection = torch.logical_and(label, output)\n",
    "        union = torch.logical_or(label, output)\n",
    "        iou_score[_cls] = torch.sum(intersection) / (torch.sum(union) + 1e-10)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        if getattr(m, 'bias') is not None:\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f73338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightConstraint(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self,module):\n",
    "        if hasattr(module,'weight'):\n",
    "            w=module.weight.data\n",
    "            w=w.clamp(0, 1)\n",
    "            module.weight.data=w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a84e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, fs_weight, preds, mask):\n",
    "        return self.ce(preds, mask) + torch.sum(1 - (torch.abs(fs_weight) / 0.99 - 1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428abd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NnModel(pl.LightningModule):\n",
    "    def __init__(self, model, loss, enable_image_logging=False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.enable_image_logging = enable_image_logging\n",
    "        #self.weight_contraint_function = WeightConstraint()\n",
    "\n",
    "    def _custom_histogram_adder(self):\n",
    "        for name,params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name,params,self.current_epoch)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=4e-3)\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        img, mask = train_batch\n",
    "        preds = self.model(img)\n",
    "        loss = self.loss(preds, mask)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        img, mask = val_batch\n",
    "        preds = self.model(img)\n",
    "        loss = self.loss(preds, mask)\n",
    "        metric = iou_pytorch(preds, mask)\n",
    "        \n",
    "        if self.enable_image_logging:\n",
    "            pred = torch.argmax(preds.detach().cpu()[0], dim=0)\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "            sns.heatmap(pred, ax=ax1, vmin=0, vmax=17)\n",
    "            sns.heatmap(mask.cpu()[0], ax=ax2, vmin=0, vmax=17)\n",
    "            fig.savefig('temp_fig.png')\n",
    "            plt.close(fig)\n",
    "            \n",
    "#             trainer.logger.experiment.log_histogram_3d(\n",
    "#                 self.model.features_selection.weight.detach().cpu().numpy(),\n",
    "#                 name='band-selection layer',\n",
    "#                 step=self.global_step\n",
    "#             )\n",
    "            if hasattr(trainer.logger.experiment, 'log_image'):\n",
    "                # For Comet logger\n",
    "                trainer.logger.experiment.log_image('temp_fig.png', name=f'{batch_idx}', overwrite=False, step=self.global_step)\n",
    "            else:\n",
    "                # For tensorboard logger\n",
    "                img = cv2.imread('temp_fig.png')\n",
    "                trainer.logger.experiment.add_image(f'{batch_idx}', img, dataformats='HWC')\n",
    "        \n",
    "        d = {f'iou_{i}': iou for i, iou in enumerate(metric)}\n",
    "        d['val_loss'] = loss\n",
    "        self.log_dict(d, on_step=False, on_epoch=True, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d86dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_explained_variance = np.load('PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load('PcaMean.npy')\n",
    "pca_components = np.load('PcaComponents.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b4acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transformation(x):\n",
    "    x_t = np.reshape(x, (x.shape[0], -1)) # (C, H, W) -> (C, H * W)\n",
    "    x_t = np.swapaxes(x_t, 0, 1) # (C, H * W) -> (H * W, C)\n",
    "    x_t = x_t - pca_mean\n",
    "    x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "    return np.reshape(x_t, (x.shape[1], x.shape[2], pca_components.shape[0])).astype(np.float32) # (H, W, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(imgs, masks):\n",
    "    target_size = (256, 256)\n",
    "    _images = [image.resize(target_size,Image.BILINEAR)\n",
    "                   for image in imgs]\n",
    "    _masks = [mask.resize(target_size, Image.BILINEAR) for mask in masks]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55211d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(imgs, masks):\n",
    "    with open('data_standartization_params.json', 'r') as f:\n",
    "        data_standartization_params = json.load(f)\n",
    "    mean = data_standartization_params.get('means')\n",
    "    std = data_standartization_params.get('stds')\n",
    "    def standartization(img):\n",
    "        return np.array((img - mean) / std, dtype=np.float32)\n",
    "    _images = [np.transpose(image, (1, 2, 0)) for image in imgs] #[pca_transformation(image) for image in imgs]\n",
    "    #_images = [standartization(image) for image in _images]\n",
    "    _masks = [\n",
    "        np.expand_dims(\n",
    "            cv2.medianBlur(cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY).astype(np.uint8), 11)\n",
    "            ,0\n",
    "        ).astype(np.int64)\n",
    "        for mask in masks\n",
    "    ]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69079a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_augmentation(image, mask):\n",
    "    image = TF.to_tensor(image)\n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    \n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16432260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(image, mask):\n",
    "    image = TF.to_tensor(image)\n",
    "    mask = torch.from_numpy(mask)\n",
    "    #angle = T.RandomRotation.get_params((-30, 30))\n",
    "    #image = TF.rotate(image, angle, interpolation=T.InterpolationMode.BILINEAR)\n",
    "    #mask = TF.rotate(mask, angle, interpolation=T.InterpolationMode.NEAREST)\n",
    "    \n",
    "    if np.random.random() > 0.5:\n",
    "        image = TF.hflip(image)\n",
    "        mask = TF.hflip(mask)\n",
    "\n",
    "    if np.random.random() > 0.5:\n",
    "        image = TF.vflip(image)\n",
    "        mask = TF.vflip(mask)\n",
    "    \n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf4601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random = np.random.permutation(np.arange(384))\n",
    "# test_indices = random[310:]\n",
    "# train_indices = random[:310]\n",
    "\n",
    "test_indices = np.load('test_indices.npy')\n",
    "train_indices = np.load('train_indices.npy')\n",
    "path = '/raid/rustam/hyperspectral_dataset/cropped_hsi_data'\n",
    "\n",
    "dataset_train = HsiDataloader(path, preprocessing=preprocessing, augmentation=augmentation, indices=train_indices)\n",
    "dataset_test = HsiDataloader(path, preprocessing=preprocessing, augmentation=test_augmentation, indices=test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb68910",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19733c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i = np.transpose(data[0], (0, 1, 2, 3))\n",
    "data_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00fa6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].cpu().detach().numpy().shape, data[1].cpu().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e51c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb005fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data_i[0][20].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_i[0][120].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcee1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.transpose(data[0][0].cpu().detach().numpy(), (1, 2, 0))[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.transpose(data[0][0].cpu().detach().numpy(), (1, 2, 0))[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ee19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba761c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6664dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Unet(in_channels=237, out_channels=17, init_features=128, pretrained=False)\n",
    "# net = net.apply(init_weights)\n",
    "    # net = UnetWithFeatureSelection(in_channels=236, out_channels=17, init_features=128, pretrained=False)\n",
    "\n",
    "# net = U2Net(17, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySuperNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_f=17, out_f=17):\n",
    "        super().__init__()\n",
    "        self.bn_start = nn.BatchNorm2d(in_f)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_f, in_f * 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_f * 2)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_f * 2, in_f * 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(in_f * 4)\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_f * 4, in_f * 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(in_f * 2)\n",
    "        self.act3 = nn.ReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_f * 2, in_f, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(in_f)\n",
    "        self.act4 = nn.ReLU()\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(in_f, out_f, kernel_size=1, stride=1, padding=0)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.bn_start(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.act3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a17000",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MySuperNet(237, 17)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3705d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net(torch.randn(1, 237, 512, 512).float()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CometLogger(\n",
    "    api_key=\"your-key\",\n",
    "    workspace=\"your-workspace\",  # Optional\n",
    "    project_name=\"your-project-name\",  # Optional\n",
    "    experiment_name=\"Test lower arch. W/o PCA/ Blur /. makiloss, updated data / gamma=2\"\n",
    ")\n",
    "\n",
    "#logger = TensorBoardLogger(\n",
    "#    'logs/'\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc03c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLossCustom(nn.Module):\n",
    "    \"\"\"\n",
    "    copy from: https://github.com/Hsuxu/Loss_ToolBox-PyTorch/blob/master/FocalLoss/FocalLoss.py\n",
    "    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
    "    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n",
    "        Focal_Loss= -1*alpha*(1-pt)*log(pt)\n",
    "    :param num_class:\n",
    "    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n",
    "    :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n",
    "                    focus on hard misclassified example\n",
    "    :param smooth: (float,double) smooth value when cross entropy\n",
    "    :param balance_index: (int) balance class index, should be specific when alpha is float\n",
    "    :param size_average: (bool, optional) By default, the losses are averaged over each loss element in the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=None, gamma=2, balance_index=2, smooth=1e-5, size_average=False):\n",
    "        super(FocalLossCustom, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.balance_index = balance_index\n",
    "        self.smooth = smooth\n",
    "        self.size_average = size_average\n",
    "        self.cel = nn.CrossEntropyLoss(reduction='none')\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        if self.smooth is not None:\n",
    "            if self.smooth < 0 or self.smooth > 1.0:\n",
    "                raise ValueError('smooth value should be in [0,1]')\n",
    "\n",
    "    def forward(self, logit, target):\n",
    "        num_class = logit.shape[1]\n",
    "\n",
    "        if logit.dim() > 2:\n",
    "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "            logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "            logit = logit.permute(0, 2, 1).contiguous()\n",
    "            logit = logit.view(-1, logit.size(-1))\n",
    "        target = torch.squeeze(target, 1)\n",
    "        target = target.view(-1, 1)\n",
    "        \n",
    "        ce_loss = self.cel(logit, target.view(-1))\n",
    "        train_conf = self.softmax(logit)\n",
    "        \n",
    "        idx = target.cpu().long()\n",
    "        one_hot_labels  = torch.FloatTensor(target.size(0), num_class).zero_()\n",
    "        one_hot_labels  = one_hot_labels.scatter_(1, idx, 1)\n",
    "        if one_hot_labels.device != logit.device:\n",
    "            one_hot_labels = one_hot_labels.to(logit.device)\n",
    "        \n",
    "        filtered_conf = train_conf * one_hot_labels\n",
    "        sparce_conf, _ = torch.max(filtered_conf, dim=-1)\n",
    "        loss = torch.pow((torch.ones_like(sparce_conf) - sparce_conf), self.gamma) * ce_loss\n",
    "        \"\"\"\n",
    "        \n",
    "        # print(logit.shape, target.shape)\n",
    "        # \n",
    "        alpha = self.alpha\n",
    "\n",
    "        if alpha is None:\n",
    "            alpha = torch.ones(num_class, 1)\n",
    "        elif isinstance(alpha, (list, np.ndarray)):\n",
    "            assert len(alpha) == num_class\n",
    "            alpha = torch.FloatTensor(alpha).view(num_class, 1)\n",
    "            alpha = alpha / alpha.sum()\n",
    "        elif isinstance(alpha, float):\n",
    "            alpha = torch.ones(num_class, 1)\n",
    "            alpha = alpha * (1 - self.alpha)\n",
    "            alpha[self.balance_index] = self.alpha\n",
    "\n",
    "        else:\n",
    "            raise TypeError('Not support alpha type')\n",
    "        \n",
    "        if alpha.device != logit.device:\n",
    "            alpha = alpha.to(logit.device)\n",
    "\n",
    "        idx = target.cpu().long()\n",
    "\n",
    "        one_hot_key = torch.FloatTensor(target.size(0), num_class).zero_()\n",
    "        one_hot_key = one_hot_key.scatter_(1, idx, 1)\n",
    "        if one_hot_key.device != logit.device:\n",
    "            one_hot_key = one_hot_key.to(logit.device)\n",
    "\n",
    "        if self.smooth:\n",
    "            one_hot_key = torch.clamp(\n",
    "                one_hot_key, self.smooth/(num_class-1), 1.0 - self.smooth)\n",
    "        pt = (one_hot_key * logit).sum(1) + self.smooth\n",
    "        logpt = pt.log()\n",
    "        \n",
    "        gamma = self.gamma\n",
    "\n",
    "        alpha = alpha[idx]\n",
    "        alpha = torch.squeeze(alpha)\n",
    "        loss = -1 * alpha * torch.pow((1 - pt), gamma) * logpt\n",
    "        \"\"\"\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        if not self.size_average:\n",
    "            # Norm by positive\n",
    "            num_positive = torch.sum(target != self.balance_index)\n",
    "            loss = loss.sum() / (num_positive + 1e-10)\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72220c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = NnModel(net, muti_bce_loss_fusion, enable_image_logging=True)\n",
    "model = NnModel(net, FocalLossCustom(), enable_image_logging=True)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, \n",
    "    max_epochs=26,\n",
    "    check_val_every_n_epoch=2,\n",
    "    logger=logger\n",
    ")\n",
    "# trainer = pl.Trainer(\n",
    "#     gpus=1, \n",
    "#     max_epochs=2000,\n",
    "#     check_val_every_n_epoch=2000)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e3e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.experiment.log_html(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a8662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ed428",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(net.features_selection.weight.detach().cpu().numpy()[::, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.zeros((17, ))\n",
    "std = np.zeros((17, ))\n",
    "count = 0\n",
    "for img, mask in train_loader:\n",
    "    img = img.detach().cpu().numpy()\n",
    "    mean += img.mean(axis=(2, 3))[0]\n",
    "    std += img.std(axis=(2, 3))[0]\n",
    "    count += 1\n",
    "mean /= count\n",
    "std /= count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f238004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data_standartization_params.json', 'w') as f:\n",
    "#     json.dump(\n",
    "#         {\n",
    "#             \"means\": mean.tolist(),\n",
    "#             \"stds\": std.tolist()\n",
    "#         }, f\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f38d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(itertools.islice(train_loader.__iter__(), 0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = net.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923fda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(17, 1, figsize=(6, 30))\n",
    "for i, ax in enumerate(axis):\n",
    "    sns.heatmap(preds[i], ax=ax, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ba81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab544292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de422ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTroch version\n",
    "\n",
    "SMOOTH = 1e-6\n",
    "\n",
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    \n",
    "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    \n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean() if you are interested in average across the batch\n",
    "    \n",
    "    \n",
    "# Numpy version\n",
    "# Well, it's the same function, so I'm going to omit the comments\n",
    "\n",
    "def iou_numpy(outputs: np.array, labels: np.array):\n",
    "    outputs = outputs.squeeze(1)\n",
    "    \n",
    "    intersection = (outputs & labels).sum((1, 2))\n",
    "    union = (outputs | labels).sum((1, 2))\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    \n",
    "    thresholded = np.ceil(np.clip(20 * (iou - 0.5), 0, 10)) / 10\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6bb112",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_val = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data_x, val_data = next(iter_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff03014",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = net(in_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584a5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np, val_data_np = preds.detach().numpy(), val_data.detach().numpy()\n",
    "preds_np.shape, val_data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np = np.argmax(preds_np, axis=1)\n",
    "preds_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac988ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_numpy(np.expand_dims(preds_np, axis=0), val_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b8150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32efd8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(preds_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28596c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(val_data_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(in_data_x[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ffe2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
