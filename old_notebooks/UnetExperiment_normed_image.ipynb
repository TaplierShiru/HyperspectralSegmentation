{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12720b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60264d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from makitorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import comet_ml\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from makitorch.architectures.U2Net import U2Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsi_dataset_api import HsiDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "from makitorch.architectures.Unet import Unet, UnetWithFeatureSelection\n",
    "from makitorch.loss import muti_bce_loss_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "    iou_score = np.zeros(outputs.shape[1])\n",
    "    outputs[outputs > 0.5] = 1\n",
    "    outputs[outputs <= 0.5] = 0\n",
    "    num_classes = outputs.shape[1]\n",
    "    for _cls in range(num_classes):\n",
    "        output = outputs[::, _cls]\n",
    "        label = torch.clone(labels[::])\n",
    "        label[label != (_cls + 1)] = 0\n",
    "        label[label == (_cls + 1)] = 1\n",
    "        intersection = torch.logical_and(label, output)\n",
    "        union = torch.logical_or(label, output)\n",
    "        iou_score[_cls] = torch.sum(intersection) / (torch.sum(union) + 1e-10)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        if getattr(m, 'bias') is not None:\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f73338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightConstraint(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self,module):\n",
    "        if hasattr(module,'weight'):\n",
    "            w=module.weight.data\n",
    "            w=w.clamp(0, 1)\n",
    "            module.weight.data=w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a84e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, fs_weight, preds, mask):\n",
    "        return self.ce(preds, mask) + torch.sum(1 - (torch.abs(fs_weight) / 0.99 - 1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428abd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NnModel(pl.LightningModule):\n",
    "    def __init__(self, model, loss, enable_image_logging=False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.enable_image_logging = enable_image_logging\n",
    "        #self.weight_contraint_function = WeightConstraint()\n",
    "\n",
    "    def _custom_histogram_adder(self):\n",
    "        for name,params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name,params,self.current_epoch)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=4e-3)\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        img, mask = train_batch\n",
    "        preds = self.model(img)\n",
    "        loss = self.loss(preds, mask)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        img, mask = val_batch\n",
    "        preds = self.model(img)\n",
    "        loss = self.loss(preds, mask)\n",
    "        metric = iou_pytorch(preds, mask)\n",
    "        \n",
    "        if self.enable_image_logging:\n",
    "            pred = torch.argmax(preds.detach().cpu()[0], dim=0)\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "            sns.heatmap(pred, ax=ax1, vmin=0, vmax=17)\n",
    "            sns.heatmap(mask.cpu()[0], ax=ax2, vmin=0, vmax=17)\n",
    "            fig.savefig('temp_fig.png')\n",
    "            plt.close(fig)\n",
    "            \n",
    "#             trainer.logger.experiment.log_histogram_3d(\n",
    "#                 self.model.features_selection.weight.detach().cpu().numpy(),\n",
    "#                 name='band-selection layer',\n",
    "#                 step=self.global_step\n",
    "#             )\n",
    "            if hasattr(trainer.logger.experiment, 'log_image'):\n",
    "                # For Comet logger\n",
    "                trainer.logger.experiment.log_image('temp_fig.png', name=f'{batch_idx}', overwrite=False, step=self.global_step)\n",
    "            else:\n",
    "                # For tensorboard logger\n",
    "                img = cv2.imread('temp_fig.png')\n",
    "                trainer.logger.experiment.add_image(f'{batch_idx}', img, dataformats='HWC')\n",
    "        \n",
    "        d = {f'iou_{i}': iou for i, iou in enumerate(metric)}\n",
    "        d['val_loss'] = loss\n",
    "        self.log_dict(d, on_step=False, on_epoch=True, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d86dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_explained_variance = np.load('PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load('PcaMean.npy')\n",
    "pca_components = np.load('PcaComponents.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b4acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transformation(x):\n",
    "    x_t = np.reshape(x, (x.shape[0], -1)) # (C, H, W) -> (C, H * W)\n",
    "    x_t = np.swapaxes(x_t, 0, 1) # (C, H * W) -> (H * W, C)\n",
    "    x_t = x_t - pca_mean\n",
    "    x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "    return np.reshape(x_t, (x.shape[1], x.shape[2], pca_components.shape[0])).astype(np.float32) # (H, W, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(imgs, masks):\n",
    "    target_size = (256, 256)\n",
    "    _images = [image.resize(target_size,Image.BILINEAR)\n",
    "                   for image in imgs]\n",
    "    _masks = [mask.resize(target_size, Image.BILINEAR) for mask in masks]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55211d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(imgs, masks):\n",
    "    with open('data_standartization_params.json', 'r') as f:\n",
    "        data_standartization_params = json.load(f)\n",
    "    mean = data_standartization_params.get('means')\n",
    "    std = data_standartization_params.get('stds')\n",
    "    def standartization(img):\n",
    "        return np.array((img - mean) / std, dtype=np.float32)\n",
    "    \n",
    "    _images = [pca_transformation(image) for image in imgs]\n",
    "    _images = [standartization(image) for image in _images]\n",
    "    _masks = [np.expand_dims(cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY).astype(np.int64), 0) for mask in masks]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69079a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_augmentation(image, mask):\n",
    "    image = TF.to_tensor(image)\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    \n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16432260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(image, mask):\n",
    "    image = TF.to_tensor(image)\n",
    "    mask = torch.from_numpy(mask)\n",
    "    print('mask=',mask.shape, ' image=', image.shape)\n",
    "    #angle = T.RandomRotation.get_params((-30, 30))\n",
    "    #image = TF.rotate(image, angle, interpolation=T.InterpolationMode.BILINEAR)\n",
    "    #mask = TF.rotate(mask, angle, interpolation=T.InterpolationMode.NEAREST)\n",
    "    \n",
    "    if np.random.random() > 0.01:\n",
    "        image = TF.hflip(image)\n",
    "        mask = TF.hflip(mask)\n",
    "    print('first flip  mask=',mask.shape, ' image=', image.shape)\n",
    "\n",
    "    if np.random.random() > 0.01:\n",
    "        image = TF.vflip(image)\n",
    "        mask = TF.vflip(mask)\n",
    "    print('second flip  mask=',mask.shape, ' image=', image.shape)\n",
    "    \n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf4601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random = np.random.permutation(np.arange(384))\n",
    "# test_indices = random[310:]\n",
    "# train_indices = random[:310]\n",
    "\n",
    "test_indices = np.load('test_indices.npy')\n",
    "train_indices = np.load('train_indices.npy')\n",
    "path = '/raid/rustam/hyperspectral_dataset/cropped_hsi_data'\n",
    "\n",
    "dataset_train = HsiDataloader(path, preprocessing=preprocessing, augmentation=augmentation, indices=train_indices)\n",
    "dataset_test = HsiDataloader(path, preprocessing=preprocessing, augmentation=test_augmentation, indices=test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb68910",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19733c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00fa6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].cpu().detach().numpy().shape, data[1].cpu().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e51c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fdd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(data[0][0].cpu().detach().numpy(), (1, 2, 0))[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcee1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.transpose(data[0][0].cpu().detach().numpy(), (1, 2, 0))[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.transpose(data[0][0].cpu().detach().numpy(), (1, 2, 0))[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ee19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba761c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6664dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Unet(in_channels=17, out_channels=17, init_features=128, pretrained=False)\n",
    "# net = net.apply(init_weights)\n",
    "    # net = UnetWithFeatureSelection(in_channels=236, out_channels=17, init_features=128, pretrained=False)\n",
    "\n",
    "# net = U2Net(17, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d3ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySuperNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, end_net: Unet, in_f=17):\n",
    "        super().__init__()\n",
    "        self.end_net = end_net\n",
    "        self.bn_start = nn.BatchNorm2d(in_f)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.bn_start(x)\n",
    "        x = self.end_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d15915",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MySuperNet(net, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CometLogger(\n",
    "    api_key=\"your-key\",\n",
    "    workspace=\"your-workspace\",  # Optional\n",
    "    project_name=\"your-project-name\",  # Optional\n",
    "    experiment_name=\"Norm image min/max // maki-style FC (gamma=4, normed by positive balance=2)\"\n",
    ")\n",
    "\n",
    "#logger = TensorBoardLogger(\n",
    "#    'logs/'\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd53561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLossCustom(nn.Module):\n",
    "    \"\"\"\n",
    "    copy from: https://github.com/Hsuxu/Loss_ToolBox-PyTorch/blob/master/FocalLoss/FocalLoss.py\n",
    "    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
    "    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n",
    "        Focal_Loss= -1*alpha*(1-pt)*log(pt)\n",
    "    :param num_class:\n",
    "    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n",
    "    :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n",
    "                    focus on hard misclassified example\n",
    "    :param smooth: (float,double) smooth value when cross entropy\n",
    "    :param balance_index: (int) balance class index, should be specific when alpha is float\n",
    "    :param size_average: (bool, optional) By default, the losses are averaged over each loss element in the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=None, gamma=2, balance_index=2, smooth=1e-5, size_average=False):\n",
    "        super(FocalLossCustom, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.balance_index = balance_index\n",
    "        self.smooth = smooth\n",
    "        self.size_average = size_average\n",
    "        self.cel = nn.CrossEntropyLoss(reduction='none')\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        if self.smooth is not None:\n",
    "            if self.smooth < 0 or self.smooth > 1.0:\n",
    "                raise ValueError('smooth value should be in [0,1]')\n",
    "\n",
    "    def forward(self, logit, target):\n",
    "        num_class = logit.shape[1]\n",
    "\n",
    "        if logit.dim() > 2:\n",
    "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "            logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "            logit = logit.permute(0, 2, 1).contiguous()\n",
    "            logit = logit.view(-1, logit.size(-1))\n",
    "        target = torch.squeeze(target, 1)\n",
    "        target = target.view(-1, 1)\n",
    "        \n",
    "        ce_loss = self.cel(logit, target.view(-1))\n",
    "        train_conf = self.softmax(logit)\n",
    "        \n",
    "        idx = target.cpu().long()\n",
    "        one_hot_labels  = torch.FloatTensor(target.size(0), num_class).zero_()\n",
    "        one_hot_labels  = one_hot_labels.scatter_(1, idx, 1)\n",
    "        if one_hot_labels.device != logit.device:\n",
    "            one_hot_labels = one_hot_labels.to(logit.device)\n",
    "        \n",
    "        filtered_conf = train_conf * one_hot_labels\n",
    "        sparce_conf, _ = torch.max(filtered_conf, dim=-1)\n",
    "        loss = torch.pow((torch.ones_like(sparce_conf) - sparce_conf), self.gamma) * ce_loss\n",
    "        \"\"\"\n",
    "        \n",
    "        # print(logit.shape, target.shape)\n",
    "        # \n",
    "        alpha = self.alpha\n",
    "\n",
    "        if alpha is None:\n",
    "            alpha = torch.ones(num_class, 1)\n",
    "        elif isinstance(alpha, (list, np.ndarray)):\n",
    "            assert len(alpha) == num_class\n",
    "            alpha = torch.FloatTensor(alpha).view(num_class, 1)\n",
    "            alpha = alpha / alpha.sum()\n",
    "        elif isinstance(alpha, float):\n",
    "            alpha = torch.ones(num_class, 1)\n",
    "            alpha = alpha * (1 - self.alpha)\n",
    "            alpha[self.balance_index] = self.alpha\n",
    "\n",
    "        else:\n",
    "            raise TypeError('Not support alpha type')\n",
    "        \n",
    "        if alpha.device != logit.device:\n",
    "            alpha = alpha.to(logit.device)\n",
    "\n",
    "        idx = target.cpu().long()\n",
    "\n",
    "        one_hot_key = torch.FloatTensor(target.size(0), num_class).zero_()\n",
    "        one_hot_key = one_hot_key.scatter_(1, idx, 1)\n",
    "        if one_hot_key.device != logit.device:\n",
    "            one_hot_key = one_hot_key.to(logit.device)\n",
    "\n",
    "        if self.smooth:\n",
    "            one_hot_key = torch.clamp(\n",
    "                one_hot_key, self.smooth/(num_class-1), 1.0 - self.smooth)\n",
    "        pt = (one_hot_key * logit).sum(1) + self.smooth\n",
    "        logpt = pt.log()\n",
    "        \n",
    "        gamma = self.gamma\n",
    "\n",
    "        alpha = alpha[idx]\n",
    "        alpha = torch.squeeze(alpha)\n",
    "        loss = -1 * alpha * torch.pow((1 - pt), gamma) * logpt\n",
    "        \"\"\"\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        if not self.size_average:\n",
    "            # Norm by positive\n",
    "            num_positive = torch.sum(target != self.balance_index)\n",
    "            loss = loss.sum() / (num_positive + 1e-10)\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72220c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = NnModel(net, muti_bce_loss_fusion, enable_image_logging=True)\n",
    "model = NnModel(net, FocalLossCustom(), enable_image_logging=True)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, \n",
    "    max_epochs=14,\n",
    "    check_val_every_n_epoch=2,\n",
    "    logger=logger\n",
    ")\n",
    "# trainer = pl.Trainer(\n",
    "#     gpus=1, \n",
    "#     max_epochs=2000,\n",
    "#     check_val_every_n_epoch=2000)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e3e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.experiment.log_html(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a8662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ed428",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(net.features_selection.weight.detach().cpu().numpy()[::, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.zeros((17, ))\n",
    "std = np.zeros((17, ))\n",
    "count = 0\n",
    "for img, mask in train_loader:\n",
    "    img = img.detach().cpu().numpy()\n",
    "    mean += img.mean(axis=(2, 3))[0]\n",
    "    std += img.std(axis=(2, 3))[0]\n",
    "    count += 1\n",
    "mean /= count\n",
    "std /= count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f238004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data_standartization_params.json', 'w') as f:\n",
    "#     json.dump(\n",
    "#         {\n",
    "#             \"means\": mean.tolist(),\n",
    "#             \"stds\": std.tolist()\n",
    "#         }, f\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f38d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(itertools.islice(train_loader.__iter__(), 0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = net.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923fda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(17, 1, figsize=(6, 30))\n",
    "for i, ax in enumerate(axis):\n",
    "    sns.heatmap(preds[i], ax=ax, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ba81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ef25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTroch version\n",
    "\n",
    "SMOOTH = 1e-6\n",
    "\n",
    "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
    "    # You can comment out this line if you are passing tensors of equal shape\n",
    "    # But if you are passing output from UNet or something it will most probably\n",
    "    # be with the BATCH x 1 x H x W shape\n",
    "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    \n",
    "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
    "    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
    "    \n",
    "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean() if you are interested in average across the batch\n",
    "    \n",
    "    \n",
    "# Numpy version\n",
    "# Well, it's the same function, so I'm going to omit the comments\n",
    "\n",
    "def iou_numpy(outputs: np.array, labels: np.array):\n",
    "    outputs = outputs.squeeze(1)\n",
    "    \n",
    "    intersection = (outputs & labels).sum((1, 2))\n",
    "    union = (outputs | labels).sum((1, 2))\n",
    "    \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    \n",
    "    thresholded = np.ceil(np.clip(20 * (iou - 0.5), 0, 10)) / 10\n",
    "    \n",
    "    return thresholded  # Or thresholded.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_val = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c4c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data_x, val_data = next(iter_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = net(in_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a89fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c335a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np, val_data_np = preds.detach().numpy(), val_data.detach().numpy()\n",
    "preds_np.shape, val_data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np = np.argmax(preds_np, axis=1)\n",
    "preds_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9038bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_numpy(np.expand_dims(preds_np, axis=0), val_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5853cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c03dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(preds_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a32cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(val_data_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(in_data_x[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae74f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
