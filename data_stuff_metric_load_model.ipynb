{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from hsi_dataset_api import HsiDataset\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_explained_variance = np.load('kfold0_PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load('kfold0_PcaMean.npy')\n",
    "pca_components = np.load('kfold0_PcaComponents.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transformation(x):\n",
    "    x_t = np.reshape(x, (x.shape[0], -1)) # (C, H, W) -> (C, H * W)\n",
    "    x_t = np.swapaxes(x_t, 0, 1) # (C, H * W) -> (H * W, C)\n",
    "    x_t = x_t - pca_mean\n",
    "    x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "    return np.reshape(x_t, (x.shape[1], x.shape[2], pca_components.shape[0])).astype(np.float32) # (H, W, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b972ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySuperNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_f=17, out_f=17):\n",
    "        super().__init__()\n",
    "        self.bn_start = nn.BatchNorm2d(in_f)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_f, in_f * 4, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(in_f * 4)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_f * 4, in_f * 8, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(in_f * 8)\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_f * 8, in_f * 4, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(in_f * 4)\n",
    "        self.act3 = nn.ReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_f * 4, in_f, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn4 = nn.BatchNorm2d(in_f)\n",
    "        self.act4 = nn.ReLU()\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(in_f, out_f, kernel_size=1, stride=1, padding=0)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.bn_start(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.act3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.act4(x)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71735d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MySuperNet(17, 17)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLossCustom(nn.Module):\n",
    "    \"\"\"\n",
    "    copy from: https://github.com/Hsuxu/Loss_ToolBox-PyTorch/blob/master/FocalLoss/FocalLoss.py\n",
    "    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
    "    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n",
    "        Focal_Loss= -1*alpha*(1-pt)*log(pt)\n",
    "    :param num_class:\n",
    "    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n",
    "    :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n",
    "                    focus on hard misclassified example\n",
    "    :param smooth: (float,double) smooth value when cross entropy\n",
    "    :param balance_index: (int) balance class index, should be specific when alpha is float\n",
    "    :param size_average: (bool, optional) By default, the losses are averaged over each loss element in the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=None, gamma=2, balance_index=2, smooth=1e-5, size_average=False):\n",
    "        super(FocalLossCustom, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.balance_index = balance_index\n",
    "        self.smooth = smooth\n",
    "        self.size_average = size_average\n",
    "        self.cel = nn.CrossEntropyLoss(reduction='none')\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        if self.smooth is not None:\n",
    "            if self.smooth < 0 or self.smooth > 1.0:\n",
    "                raise ValueError('smooth value should be in [0,1]')\n",
    "\n",
    "    def forward(self, logit, target):\n",
    "        num_class = logit.shape[1]\n",
    "\n",
    "        if logit.dim() > 2:\n",
    "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "            logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "            # N,C,m -> N,m,C\n",
    "            logit = logit.permute(0, 2, 1).contiguous()\n",
    "            # N,m,C -> N,m*C\n",
    "            logit = logit.view(-1, logit.size(-1))\n",
    "        target = torch.squeeze(target, 1)\n",
    "        target = target.view(-1, 1)\n",
    "        \n",
    "        ce_loss = self.cel(logit, target.view(-1))\n",
    "        train_conf = self.softmax(logit)\n",
    "        \n",
    "        idx = target.cpu().long()\n",
    "        one_hot_labels  = torch.FloatTensor(target.size(0), num_class).zero_()\n",
    "        one_hot_labels  = one_hot_labels.scatter_(1, idx, 1)\n",
    "        if one_hot_labels.device != logit.device:\n",
    "            one_hot_labels = one_hot_labels.to(logit.device)\n",
    "        \n",
    "        filtered_conf = train_conf * one_hot_labels\n",
    "        sparce_conf, _ = torch.max(filtered_conf, dim=-1)\n",
    "        loss = torch.pow((torch.ones_like(sparce_conf) - sparce_conf), self.gamma) * ce_loss\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        if not self.size_average:\n",
    "            # Norm by positive\n",
    "            num_positive = torch.sum(target != self.balance_index)\n",
    "            loss = loss.sum() / (num_positive + 1e-10)\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NnModel(pl.LightningModule):\n",
    "    def __init__(self, model, loss, experiment=None, enable_image_logging=True):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.experiment = experiment\n",
    "        self.enable_image_logging = enable_image_logging\n",
    "        #self.weight_contraint_function = WeightConstraint()\n",
    "\n",
    "    def _custom_histogram_adder(self):\n",
    "        for name,params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name,params,self.current_epoch)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.94)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        img, mask = train_batch\n",
    "        preds = self.model(img)\n",
    "        loss = self.loss(preds, mask)\n",
    "        self.log('train_loss', loss)\n",
    "        if self.experiment is not None:\n",
    "            self.experiment.log_metric(\"train_loss\", loss, epoch=self.current_epoch, step=self.global_step)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return batch\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        print('Size epoch end input: ', len(outputs))\n",
    "        \n",
    "        pred_tensor, target_tensor = collect_prediction_and_target(outputs, self.model)\n",
    "        target_one_hotted_tensor = list_target_to_onehot(target_tensor)\n",
    "        dice_loss_val = dice_loss(pred_tensor, target_one_hotted_tensor, dim=[0, 2, 3], use_softmax=True, softmax_dim=1)\n",
    "        metric, loss_list, pred_as_mask_list = calculate_iou(pred_tensor, target_tensor, loss=self.loss)\n",
    "        \n",
    "        for batch_idx, (loss_s, metric_s, target_s, pred_s) in enumerate(zip(loss_list, metric, target_tensor, pred_as_mask_list)):\n",
    "            if self.enable_image_logging:\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "                sns.heatmap(pred_s, ax=ax1, vmin=0, vmax=17)\n",
    "                sns.heatmap(target_s.cpu().detach().numpy(), ax=ax2, vmin=0, vmax=17)\n",
    "                fig.savefig('temp_fig.png')\n",
    "                plt.close(fig)\n",
    "\n",
    "    #             trainer.logger.experiment.log_histogram_3d(\n",
    "    #                 self.model.features_selection.weight.detach().cpu().numpy(),\n",
    "    #                 name='band-selection layer',\n",
    "    #                 step=self.global_step\n",
    "    #             )\n",
    "                if self.experiment is not None:\n",
    "                    # For Comet logger\n",
    "                    self.experiment.log_image(\n",
    "                        'temp_fig.png', name=f'{batch_idx}', \n",
    "                        overwrite=False, step=self.global_step\n",
    "                    )\n",
    "            \n",
    "            d = {f'iou_{i}': iou for i, iou in enumerate(metric_s)}\n",
    "            \n",
    "            if self.experiment is not None:\n",
    "                self.experiment.log_metrics(d, epoch=self.current_epoch)\n",
    "            else:\n",
    "                print(d)\n",
    "                \n",
    "            d = {f'loss_image_{batch_idx}': torch.tensor(loss_s, dtype=torch.float) }\n",
    "            if self.experiment is not None:\n",
    "                self.experiment.log_metrics(d, epoch=self.current_epoch)\n",
    "            else:\n",
    "                print(d)\n",
    "        if self.experiment is not None:\n",
    "            # Add confuse matrix\n",
    "            self.experiment.log_confusion_matrix(\n",
    "                target_tensor.cpu().detach().numpy().reshape(-1), \n",
    "                np.asarray(pred_as_mask_list).reshape(-1)\n",
    "            )\n",
    "            \n",
    "        mean_per_class_metric, mean_metric = clear_metric_calculation(metric, target_tensor, pred_tensor)\n",
    "        mean_dice_loss_per_class_dict = {\n",
    "            f\"mean_dice_loss_per_class_{i}\": torch.tensor(d_l, dtype=torch.float)\n",
    "            for i, d_l in enumerate(dice_loss_val)\n",
    "        }\n",
    "        mean_dice_loss_dict = {\n",
    "            f\"mean_dice_loss\": torch.tensor(dice_loss_val.mean(), dtype=torch.float)\n",
    "        }\n",
    "        mean_iou_class_dict = {\n",
    "            f\"mean_iou_class_{i}\": torch.tensor(iou, dtype=torch.float)\n",
    "            for i, iou in enumerate(mean_per_class_metric)\n",
    "        }\n",
    "        mean_iou_dict = {\n",
    "            \"mean_iou\": torch.tensor(mean_metric, dtype=torch.float),\n",
    "        }\n",
    "        mean_loss_dict = {\n",
    "            \"mean_loss\": torch.tensor(np.asarray(loss_list).mean(), dtype=torch.float),\n",
    "        }\n",
    "        \n",
    "        # Log this metric in order to save checkpoint of experements\n",
    "        self.log_dict(mean_iou_dict)\n",
    "        \n",
    "        if self.experiment is not None:\n",
    "        \n",
    "            self.experiment.log_metrics(\n",
    "                mean_dice_loss_per_class_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "\n",
    "            self.experiment.log_metrics(\n",
    "                mean_dice_loss_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "\n",
    "            self.experiment.log_metrics(\n",
    "                mean_iou_class_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "\n",
    "            self.experiment.log_metrics(\n",
    "                mean_iou_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "\n",
    "            self.experiment.log_metrics(\n",
    "                mean_loss_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "        else:\n",
    "            print(mean_dice_loss_per_class_dict)\n",
    "            print(mean_dice_loss_dict)\n",
    "            print(mean_iou_class_dict)\n",
    "            print(mean_iou_dict)\n",
    "            print(mean_loss_dict)\n",
    "            print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c42b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "w_sorted = sorted(glob.glob('diff_exp/test_kfold/kfold0/pytorch_li_logs/' +\\\n",
    "          '(run=3)kfold0-test_LrCosine W weight decay lower_arch_50ep_W full '+\\\n",
    "          'PCA._RustamPreprocess(k=1)_makiloss_gamma=5.5_balance=2__cosine(t_0=2,t_mul=1)' +\\\n",
    "          '__weiht_decay=0/*'), \n",
    "       key=lambda x: -float(x.split('/')[-1].split('-')[-1][9:13])\n",
    ")\n",
    "\n",
    "pick_best_one = w_sorted[0]\n",
    "w_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.conv1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.conv1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NnModel.load_from_checkpoint(\n",
    "    pick_best_one,\n",
    "    loss=FocalLossCustom(gamma=5.5), model=net\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1962fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model.model\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b88000",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.load('kfold0_indx_test.npy')\n",
    "train_indices = np.load('kfold0_indx_train.npy')\n",
    "path = '/raid/rustam/hyperspectral_dataset/cropped_hsi_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_augmentation(image, mask):\n",
    "    image = TF.to_tensor(image)\n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    \n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask\n",
    "\n",
    "def preprocess_mask(mask):\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "\n",
    "    erosion = cv2.erode(mask, kernel, iterations = 1)\n",
    "    dilation = cv2.dilate(erosion, kernel,iterations = 4)\n",
    "    mask_filtered = cv2.erode(dilation, kernel, iterations = 1)\n",
    "    return mask_filtered\n",
    "\n",
    "\n",
    "def preprocessing(imgs, masks):\n",
    "    with open(f'data_standartization_params_kfold0.json', 'r') as f:\n",
    "        data_standartization_params = json.load(f)\n",
    "    mean = data_standartization_params.get('means')\n",
    "    std = data_standartization_params.get('stds')\n",
    "    def standartization(img):\n",
    "        return np.array((img - mean) / std, dtype=np.float32)\n",
    "    _images = [pca_transformation(image) for image in imgs]\n",
    "    _images = [standartization(image) for image in _images]\n",
    "    _masks = [\n",
    "        np.expand_dims(\n",
    "            preprocess_mask(cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY).astype(np.uint8))\n",
    "            ,0\n",
    "        ).astype(np.int64)\n",
    "        for mask in masks\n",
    "    ]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = HsiDataloader(path, preprocessing=preprocessing, augmentation=test_augmentation, indices=test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c16620",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390daea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f101f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_list = []\n",
    "target_list = []\n",
    "\n",
    "for img_s, mask_s in tqdm(val_loader):\n",
    "    pred = net(img_s)\n",
    "    pred = nn.functional.softmax(pred, dim=1)\n",
    "    pred = pred.cpu().detach().numpy()\n",
    "    pred = np.transpose(pred, [0, 2, 3, 1])\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "    \n",
    "    mask_s = torch.squeeze(mask_s).cpu().detach().numpy()\n",
    "    preds_list.append(pred)\n",
    "    target_list.append(mask_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdf68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(preds_list[indx][0], vmax=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d19726",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(target_list[indx], vmax=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0912ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(target_list).reshape(-1),\n",
    "    np.asarray(preds_list).reshape(-1), \n",
    "    average='macro'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270ff41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(target_list).reshape(-1),\n",
    "    np.asarray(preds_list).reshape(-1), \n",
    "    average='weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02508b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(target_list).reshape(-1),\n",
    "    np.asarray(preds_list).reshape(-1), \n",
    "    average=None\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
