{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from hsi_dataset_api import HsiDataset\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "# Script with experiment code\n",
    "from my_super_net_wo_bn_parts_segmentation_diff_window_size import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_window=(16, 16); image_shape=(512, 512); num_classes=17; divided_batch=4; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5237683",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MySuperNetLittleInput(17, 17)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    _ = net(torch.randn(1, 17, cut_window[0], cut_window[1]))\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c42b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "filename = '(run=2)MySuperNetLittleInput Segmentation  cut_window=(16, 16)  rerun=1| _LrCosine W weight decay lower_arch_10ep_Wo full PCA._RustamPreprocess(k=1)_CEcosine(t_0=2,t_mul=1) | arch_type=MySuperNetLittleInput | batch_size=128 lr=0.001'\n",
    "w_sorted = sorted(glob.glob(f'pytorch_li_logs/{filename}/*'), \n",
    "       key=lambda x: -float(x.split('/')[-1].split('-')[-1][9:13])\n",
    ")\n",
    "\n",
    "pick_best_one = w_sorted[0]\n",
    "w_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NnModel.load_from_checkpoint(\n",
    "    pick_best_one,\n",
    "    loss=None, model=net\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1962fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "net = model.model\n",
    "net.to(device=device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_test.npy')\n",
    "# Test\n",
    "dataset_creator_test = DatasetCreator(\n",
    "    PATH_DATA, preprocessing=preprocessing, \n",
    "    indices=test_indices, cut_window=None,\n",
    "    create_shared_memory=False\n",
    ")\n",
    "dataset_test = HsiDataloaderCutter(\n",
    "    images=dataset_creator_test.images, masks=dataset_creator_test.masks,\n",
    "    augmentation=test_augmentation,\n",
    "    shuffle_data=False, cut_window=None,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f101f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_preds_list = []\n",
    "all_target_list = []\n",
    "\n",
    "for in_data_x, val_data in tqdm(test_loader): # max test size == 39\n",
    "    batch_size = in_data_x.shape[0]\n",
    "    # We will cut image into peases and stack it into single BIG batch\n",
    "    h_win, w_win = cut_window\n",
    "    h_parts, w_parts = image_shape[1] // w_win, image_shape[0] // h_win\n",
    "    in_data_x_parts_list = cut_into_parts_model_input(\n",
    "        in_data_x, h_parts=h_parts, \n",
    "        w_parts=w_parts, h_win=h_win, w_win=w_win\n",
    "    )\n",
    "    in_data_x_batch = torch.cat(in_data_x_parts_list, dim=0) # (N, 17, 1, 1)\n",
    "    # Make predictions via batch in order to \n",
    "    # speed up calculation and do not eat all memory\n",
    "    part_divided = len(in_data_x_batch) // divided_batch\n",
    "    pred_batch_list = []\n",
    "\n",
    "    for b_i in range(part_divided):\n",
    "        if b_i == (part_divided - 1):\n",
    "            # last\n",
    "            single_batch = in_data_x_batch[b_i * divided_batch:]\n",
    "        else:\n",
    "            single_batch = in_data_x_batch[b_i * divided_batch: (b_i+1) * divided_batch]\n",
    "        # Make predictions\n",
    "        with torch.no_grad():\n",
    "            data = single_batch.to(device=device)\n",
    "            preds = net(data).cpu().detach() # (divided_batch, C, H, W)\n",
    "        pred_batch_list.append(preds)\n",
    "    pred_batch_tensor = torch.cat(pred_batch_list, dim=0)\n",
    "    pred_mask = merge_parts_into_single_mask(\n",
    "        preds=pred_batch_tensor, shape=(batch_size, num_classes, image_shape[0], image_shape[1]), # (N, 17, 512, 512) \n",
    "        h_parts=h_parts, w_parts=w_parts, h_win=h_win, w_win=w_win\n",
    "    )\n",
    "    all_preds_list.append(pred_mask) \n",
    "    all_target_list.append(val_data)\n",
    "\n",
    "all_preds_mask_list = [\n",
    "    torch.argmax(torch.nn.functional.softmax(preds, dim=1), dim=1)\n",
    "    for preds in all_preds_list\n",
    "]\n",
    "\n",
    "\n",
    "all_preds_tensor = torch.cat(all_preds_list, dim=0)\n",
    "all_target_tensor = torch.cat(all_target_list, dim=0).squeeze()\n",
    "all_preds_mask_tensor = torch.cat(all_preds_mask_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_tensor.shape, all_target_tensor.shape, all_preds_mask_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898eac24",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4937f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb8a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(pred_list, target_list, num_classes=17):\n",
    "    res_list = []\n",
    "    pred_as_mask_list = []\n",
    "\n",
    "    for preds, target in zip(pred_list, target_list):\n",
    "        # preds - (num_classes, H, W)\n",
    "        preds = nn.functional.softmax(preds, dim=0).cpu().detach().numpy()\n",
    "        preds = np.argmax(preds, axis=0)\n",
    "        pred_as_mask_list.append(preds)\n",
    "        # target - (H, W)\n",
    "        target = target.cpu().detach().numpy()\n",
    "\n",
    "        preds_one_hoted = matrix2onehot(preds, num_classes=num_classes)\n",
    "        target_one_hoted = matrix2onehot(target, num_classes=num_classes)\n",
    "        res = f1_score(target_one_hoted, preds_one_hoted, average=None, zero_division=1)\n",
    "        res_list.append(\n",
    "            res\n",
    "        )\n",
    "\n",
    "    res_np = np.stack(res_list)\n",
    "    #res_np = res_np.mean(axis=0)\n",
    "    return res_np, pred_as_mask_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814179a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_big_image(tensor, single_elem_shape):\n",
    "    shape = tensor.shape\n",
    "    tensor = torch.cat([\n",
    "        t_s.view(*single_elem_shape)\n",
    "        for t_s in tensor\n",
    "    ], dim=-1)\n",
    "    return tensor\n",
    "\n",
    "pred_big_tensor = create_big_image(torch.clone(all_preds_tensor), single_elem_shape=[1, 17, 512, 512]) # Final shape!\n",
    "pred_mask_big_tensor = create_big_image(torch.clone(all_preds_mask_tensor), single_elem_shape=[1, 512, 512]) # Final shape!\n",
    "target_big_tensor = create_big_image(torch.clone(all_target_tensor), single_elem_shape=[1, 512, 512])  # Final shape!\n",
    "\n",
    "target_one_hotted_tensor = torch.nn.functional.one_hot(\n",
    "    target_big_tensor, 17 # Num classes\n",
    ")\n",
    "# (N, H, W, C) --> (N, C, H, W)\n",
    "target_one_hotted_tensor = target_one_hotted_tensor.permute(0, -1, 1, 2)\n",
    "dice_loss_val = dice_loss(\n",
    "    pred_big_tensor, target_one_hotted_tensor, \n",
    "    dim=[0, 2, 3], use_softmax=True, softmax_dim=1,\n",
    ")\n",
    "metric = calculate_iou(pred_big_tensor, target_big_tensor)\n",
    "f1_metric = calculate_f1(pred_big_tensor, target_big_tensor)\n",
    "\n",
    "if isinstance(metric, tuple):\n",
    "    metric = metric[0]\n",
    "    \n",
    "if isinstance(f1_metric, tuple):\n",
    "    f1_metric = f1_metric[0]\n",
    "\n",
    "\n",
    "# Show metrics results\n",
    "mean_dice = dice_loss_val.mean().float()\n",
    "mean_dice_per_class = dice_loss_val.float()\n",
    "mean_iou = metric.mean()\n",
    "mean_iou_per_class = metric.mean(axis=0)\n",
    "mean_f1 = f1_metric.mean()\n",
    "mean_f1_per_class = f1_metric.mean(axis=1)\n",
    "\n",
    "print(f\"Mean dice = {mean_dice}\")\n",
    "print(\"Mean dice per class:\")\n",
    "for i in range(17):\n",
    "    print(f\"| class={i} dice={mean_dice_per_class[i]}\")\n",
    "\n",
    "print(f\"Mean iou = {mean_iou}\")\n",
    "print(\"Mean iou per class:\")\n",
    "for i in range(17):\n",
    "    print(f\"| class={i} iou={mean_iou_per_class[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a314ef3",
   "metadata": {},
   "source": [
    "## f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0912ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a241d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "macro = f1_score(\n",
    "    np.asarray(target_big_tensor).reshape(-1),\n",
    "    np.asarray(pred_mask_big_tensor).reshape(-1), \n",
    "    average='macro'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270ff41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weighted = f1_score(\n",
    "    np.asarray(target_big_tensor).reshape(-1),\n",
    "    np.asarray(pred_mask_big_tensor).reshape(-1), \n",
    "    average='weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02508b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class = f1_score(\n",
    "    np.asarray(target_big_tensor).reshape(-1),\n",
    "    np.asarray(pred_mask_big_tensor).reshape(-1), \n",
    "    average=None\n",
    ")\n",
    "per_class = per_class.tolist()\n",
    "per_class.append(macro)\n",
    "per_class.append(weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(0, 17).tolist()\n",
    "indices.append('macro')\n",
    "indices.append('weighted')\n",
    "df = pd.DataFrame(data=per_class, index=indices).round(3)\n",
    "df.to_excel(f\"{str(cut_window)}.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56059208",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(cut_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6714595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
