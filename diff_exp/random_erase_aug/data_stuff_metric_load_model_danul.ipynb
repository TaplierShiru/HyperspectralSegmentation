{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from hsi_dataset_api import HsiDataset\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "# Script with experiment code\n",
    "from my_super_net_parts_diff_window_size_opt_change_lr_dyn_new_augs import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_window=(128, 128); image_shape=(512, 512); num_classes=17; divided_batch=4; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5237683",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MySuperNetLittleInput(17, 17)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    _ = net(torch.randn(1, 17, cut_window[0], cut_window[1]))\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c42b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "w_sorted = sorted(glob.glob('pytorch_li_logs/rerun=1/(run=1)Erase_test_cut_window=(128, 128)_change_lr_dyn_arch_200ep_PCA_RustamPreprocess(k=1)_CE_cosine(t_0=2,t_mul=1)_arch_type=MySuperNetLittleInput_batch_size=128_lr=0.001/*'), \n",
    "       key=lambda x: -float(x.split('/')[-1].split('-')[-1][9:13])\n",
    ")\n",
    "\n",
    "pick_best_one = w_sorted[0]\n",
    "w_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NnModel.load_from_checkpoint(\n",
    "    pick_best_one,\n",
    "    loss=None, model=net\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1962fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "net = model.model\n",
    "net.to(device=device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_test.npy')\n",
    "# Test\n",
    "dataset_creator_test = DatasetCreator(\n",
    "    PATH_DATA, preprocessing=preprocessing, \n",
    "    indices=test_indices, cut_window=None,\n",
    "    create_shared_memory=False\n",
    ")\n",
    "dataset_test = HsiDataloaderCutter(\n",
    "    images=dataset_creator_test.images, masks=dataset_creator_test.masks,\n",
    "    augmentation=test_augmentation,\n",
    "    shuffle_data=False, cut_window=None,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f101f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_preds_list = []\n",
    "all_target_list = []\n",
    "\n",
    "for in_data_x, val_data in tqdm(test_loader): # max test size == 39\n",
    "    batch_size = in_data_x.shape[0]\n",
    "    # We will cut image into peases and stack it into single BIG batch\n",
    "    h_win, w_win = cut_window\n",
    "    h_parts, w_parts = image_shape[1] // w_win, image_shape[0] // h_win\n",
    "    in_data_x_parts_list = cut_into_parts_model_input(\n",
    "        in_data_x, h_parts=h_parts, \n",
    "        w_parts=w_parts, h_win=h_win, w_win=w_win\n",
    "    )\n",
    "    in_data_x_batch = torch.cat(in_data_x_parts_list, dim=0) # (N, 17, 1, 1)\n",
    "    # Make predictions via batch in order to \n",
    "    # speed up calculation and do not eat all memory\n",
    "    part_divided = len(in_data_x_batch) // divided_batch\n",
    "    pred_batch_list = []\n",
    "\n",
    "    for b_i in range(part_divided):\n",
    "        if b_i == (part_divided - 1):\n",
    "            # last\n",
    "            single_batch = in_data_x_batch[b_i * divided_batch:]\n",
    "        else:\n",
    "            single_batch = in_data_x_batch[b_i * divided_batch: (b_i+1) * divided_batch]\n",
    "        # Make predictions\n",
    "        with torch.no_grad():\n",
    "            data = single_batch.to(device=device)\n",
    "            preds = net(data).cpu().detach() # (divided_batch, C, H, W)\n",
    "        pred_batch_list.append(preds)\n",
    "    pred_batch_tensor = torch.cat(pred_batch_list, dim=0)\n",
    "    pred_mask = merge_parts_into_single_mask(\n",
    "        preds=pred_batch_tensor, shape=(batch_size, num_classes, image_shape[0], image_shape[1]), # (N, 17, 512, 512) \n",
    "        h_parts=h_parts, w_parts=w_parts, h_win=h_win, w_win=w_win\n",
    "    )\n",
    "    all_preds_list.append(pred_mask) \n",
    "    all_target_list.append(val_data)\n",
    "\n",
    "all_preds_mask_list = [\n",
    "    torch.argmax(torch.nn.functional.softmax(preds, dim=1), dim=1)\n",
    "    for preds in all_preds_list\n",
    "]\n",
    "\n",
    "\n",
    "all_preds_tensor = torch.cat(all_preds_list, dim=0)\n",
    "all_target_tensor = torch.cat(all_target_list, dim=0).squeeze()\n",
    "all_preds_mask_tensor = torch.cat(all_preds_mask_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_tensor.shape, all_target_tensor.shape, all_preds_mask_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de89b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "sns.heatmap(all_preds_mask_tensor[0], vmin=0, vmax=17)\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "sns.heatmap(all_target_tensor[0], vmin=0, vmax=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "sns.heatmap(all_preds_mask_tensor[1], vmin=0, vmax=17)\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "sns.heatmap(all_target_tensor[1], vmin=0, vmax=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "fig.add_subplot(1, 2, 1)\n",
    "sns.heatmap(all_preds_mask_tensor[2], vmin=0, vmax=17)\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "sns.heatmap(all_target_tensor[2], vmin=0, vmax=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e2715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6636c115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "898eac24",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814179a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_big_image(tensor, single_elem_shape):\n",
    "    shape = tensor.shape\n",
    "    tensor = torch.cat([\n",
    "        t_s.view(*single_elem_shape)\n",
    "        for t_s in tensor\n",
    "    ], dim=-1)\n",
    "    return tensor\n",
    "\n",
    "pred_big_tensor = create_big_image(torch.clone(all_preds_tensor), single_elem_shape=[1, 17, 512, 512]) # Final shape!\n",
    "pred_mask_big_tensor = create_big_image(torch.clone(all_preds_mask_tensor), single_elem_shape=[1, 512, 512]) # Final shape!\n",
    "target_big_tensor = create_big_image(torch.clone(all_target_tensor), single_elem_shape=[1, 512, 512])  # Final shape!\n",
    "\n",
    "target_one_hotted_tensor = torch.nn.functional.one_hot(\n",
    "    target_big_tensor, 17 # Num classes\n",
    ")\n",
    "# (N, H, W, C) --> (N, C, H, W)\n",
    "target_one_hotted_tensor = target_one_hotted_tensor.permute(0, -1, 1, 2)\n",
    "dice_loss_val = dice_loss(\n",
    "    pred_big_tensor, target_one_hotted_tensor, \n",
    "    dim=[0, 2, 3], use_softmax=True, softmax_dim=1,\n",
    ")\n",
    "metric = calculate_iou(pred_big_tensor, target_big_tensor)\n",
    "\n",
    "if isinstance(metric, tuple):\n",
    "    metric = metric[0]\n",
    "\n",
    "\n",
    "# Show metrics results\n",
    "mean_dice = dice_loss_val.mean().float()\n",
    "mean_dice_per_class = dice_loss_val.float()\n",
    "mean_iou = metric.mean()\n",
    "mean_iou_per_class = metric.mean(axis=0)\n",
    "\n",
    "\n",
    "print(f\"Mean dice = {mean_dice}\")\n",
    "print(\"Mean dice per class:\")\n",
    "for i in range(17):\n",
    "    print(f\"| class={i} dice={mean_dice_per_class[i]}\")\n",
    "\n",
    "print(f\"Mean iou = {mean_iou}\")\n",
    "print(\"Mean iou per class:\")\n",
    "for i in range(17):\n",
    "    print(f\"| class={i} iou={mean_iou_per_class[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a314ef3",
   "metadata": {},
   "source": [
    "## f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0912ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a241d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(target_big_tensor).reshape(-1),\n",
    "    np.asarray(pred_mask_big_tensor).reshape(-1), \n",
    "    average='macro'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270ff41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(target_big_tensor).reshape(-1),\n",
    "    np.asarray(pred_mask_big_tensor).reshape(-1), \n",
    "    average='weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02508b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(target_big_tensor).reshape(-1),\n",
    "    np.asarray(pred_mask_big_tensor).reshape(-1), \n",
    "    average=None\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
