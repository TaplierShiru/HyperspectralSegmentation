{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from hsi_dataset_api import HsiDataset\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01675d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_INFO_PATH = '/home/rustam/hyperspecter_segmentation/danil_cave/kfolds_data/kfold0'\n",
    "PATH_DATA = '/raid/rustam/hyperspectral_dataset/new_cropped_hsi_data'\n",
    "\n",
    "\n",
    "pca_explained_variance = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaMean.npy')\n",
    "pca_components = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaComponents.npy')\n",
    "\n",
    "\n",
    "test_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_test.npy')\n",
    "train_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_train.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff92a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_augmentation(image, mask):\n",
    "    image = TF.to_tensor(image)\n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    \n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def preprocessing(imgs, masks):\n",
    "    _images = [np.transpose(image, (1, 2, 0)) for image in imgs]\n",
    "    _masks = [\n",
    "        np.expand_dims(\n",
    "            cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "            ,0\n",
    "        ).astype(np.int64)\n",
    "        for mask in masks\n",
    "    ]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = HsiDataloader(\n",
    "    PATH_DATA, preprocessing=preprocessing, \n",
    "    augmentation=test_augmentation, indices=test_indices\n",
    ")\n",
    "\n",
    "dataset_train = HsiDataloader(\n",
    "    PATH_DATA, preprocessing=preprocessing,\n",
    "    augmentation=test_augmentation, indices=train_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1)\n",
    "\n",
    "val_loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48712a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = val_loader_train\n",
    "\n",
    "specter_list = []\n",
    "target_list = []\n",
    "\n",
    "for img_s, mask_s in tqdm(val_loader):\n",
    "    specter_list.append(img_s[0].numpy())\n",
    "    target_list.append(mask_s[0].numpy())\n",
    "len(specter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ans = np.transpose(specter_list[0:1].copy(), (0, 2, 3, 1)).reshape(-1, 237)\n",
    "Ytest = np.asarray(target_list[0:1]).copy().reshape(-1)\n",
    "\n",
    "X_ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff934fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)\n",
    "reduced = pca.fit_transform(X_ans)\n",
    "plt.scatter(reduced[:,0],reduced[:,1] ,s=20,c=Ytest[:X_ans.shape[0]],alpha=0.5)\n",
    "plt.savefig('after_train1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE()\n",
    "Z = tsne.fit_transform(X_ans)\n",
    "plt.scatter(Z[:,0],Z[:,1] ,s=100,c=Ytest[:X_ans.shape[0]],alpha=0.5)\n",
    "plt.savefig('sas2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b26c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8c52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(X_ans)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding[:,0],embedding[:,1] ,s=100,c=Ytest[:X_ans.shape[0]],alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f68e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
