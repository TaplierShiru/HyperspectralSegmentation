{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from hsi_dataset_api import HsiDataset\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_INFO_PATH = '/home/rustam/hyperspecter_segmentation/danil_cave/kfolds_data/kfold0'\n",
    "\n",
    "\n",
    "pca_explained_variance = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaMean.npy')\n",
    "pca_components = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaComponents.npy')\n",
    "test_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_test.npy')\n",
    "train_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_train.npy')\n",
    "\n",
    "path = '/raid/rustam/hyperspectral_dataset/new_cropped_hsi_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transformation(x):\n",
    "    x_t = np.reshape(x, (x.shape[0], -1)) # (C, H, W) -> (C, H * W)\n",
    "    x_t = np.swapaxes(x_t, 0, 1) # (C, H * W) -> (H * W, C)\n",
    "    x_t = x_t - pca_mean\n",
    "    x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "    return np.reshape(x_t, (x.shape[1], x.shape[2], pca_components.shape[0])).astype(np.float32) # (H, W, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_augmentation(image, mask):\n",
    "    image = TF.to_tensor(image)\n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    \n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def mask2class(mask):\n",
    "    # Calculate which class have more pixel count\n",
    "    max_value = -1\n",
    "    pixel_count = -1\n",
    "    for class_indx in np.unique(mask):\n",
    "        pix_count_s = np.sum(mask == class_indx)\n",
    "        if pix_count_s > pixel_count:\n",
    "            max_value = class_indx\n",
    "            pixel_count = pix_count_s\n",
    "    assert max_value != -1\n",
    "    return np.array([max_value], dtype=np.int64) \n",
    "\n",
    "\n",
    "def preprocessing(imgs, masks, cut_window=None):\n",
    "    with open(f'{PREFIX_INFO_PATH}/data_standartization_params_kfold0.json', 'r') as f:\n",
    "        data_standartization_params = json.load(f)\n",
    "    mean = data_standartization_params.get('means')\n",
    "    std = data_standartization_params.get('stds')\n",
    "    assert mean is not None and std is not None\n",
    "    def standartization(img):\n",
    "        return np.array((img - mean) / std, dtype=np.float32)\n",
    "    _images = [np.transpose(image, (1, 2, 0)) for image in imgs] #[pca_transformation(image) for image in imgs]\n",
    "    #_images = [standartization(image) for image in _images]\n",
    "    _masks = [\n",
    "        np.expand_dims(\n",
    "            cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "            ,0\n",
    "        ).astype(np.int64)\n",
    "        for mask in masks\n",
    "    ]\n",
    "    if cut_window is not None:\n",
    "        _masks = [mask2class(mask) for mask in _masks]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7925dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from makitorch.data_tools.augmentation import DataAugmentator\n",
    "from makitorch.data_tools.augmentation import BaseDataAugmentor\n",
    "from makitorch.data_tools.preprocessing import BaseDataPreprocessor\n",
    "from makitorch.data_tools.preprocessing import DataPreprocessor\n",
    "\n",
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "from hsi_dataset_api import HsiDataset\n",
    "\n",
    "\n",
    "class HsiDataloaderCutter(torch.utils.data.IterableDataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            data_path: str,\n",
    "            preprocessing: Optional[Union[DataPreprocessor, Callable]] = BaseDataPreprocessor(),\n",
    "            augmentation: Optional[Union[DataAugmentator, Callable]] = BaseDataAugmentor(),\n",
    "            indices = None,\n",
    "            shuffle_data=False,\n",
    "            cut_window=(8, 8)\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.shuffle_data = shuffle_data\n",
    "        self.dataset = HsiDataset(data_path)\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        \n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        \n",
    "        for idx, data_point in enumerate(self.dataset.data_iterator(opened=True, shuffle=False)):\n",
    "            if indices is not None and idx not in indices:\n",
    "                continue\n",
    "            image, mask = data_point.hsi, data_point.mask\n",
    "            if cut_window is not None:\n",
    "                image_parts, mask_parts = self._cut_with_window(image, mask, cut_window)\n",
    "                self.images += image_parts\n",
    "                self.masks += mask_parts\n",
    "            else:\n",
    "                self.images.append(image)\n",
    "                self.masks.append(mask)\n",
    "        \n",
    "        if self.preprocessing is not None:\n",
    "            self.images, self.masks = self.preprocessing(self.images, self.masks)\n",
    "    \n",
    "    def _cut_with_window(self, image, mask, cut_window):\n",
    "        assert len(cut_window) == 2\n",
    "        h_win, w_win = cut_window\n",
    "        _, h, w = image.shape\n",
    "        h_parts = h // h_win\n",
    "        w_parts = w // w_win\n",
    "        if h % h_win != 0:\n",
    "            print(f\"{h % h_win} pixels will be dropped by h axis. Input shape={image.shape}\")\n",
    "\n",
    "        if w % w_win != 0:\n",
    "            print(f\"{w % w_win} pixels will be dropped by w axis. Input shape={image.shape}\")\n",
    "\n",
    "        image_parts_list = []\n",
    "        mask_parts_list = []\n",
    "\n",
    "        for h_i in range(h_parts):\n",
    "            for w_i in range(w_parts):\n",
    "                img_part = image[:, \n",
    "                    h_i * h_win: (h_i+1) * h_win, \n",
    "                    w_i * w_win: (w_i+1) * w_win\n",
    "                ]\n",
    "                mask_part = mask[\n",
    "                    h_i * h_win: (h_i+1) * h_win, \n",
    "                    w_i * w_win: (w_i+1) * w_win\n",
    "                ]\n",
    "\n",
    "                image_parts_list.append(img_part)\n",
    "                mask_parts_list.append(mask_part)\n",
    "        return image_parts_list, mask_parts_list\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle_data:\n",
    "            self.images, self.masks = shuffle(self.images, self.masks)\n",
    "        \n",
    "        for image, mask in zip(self.images, self.masks):\n",
    "            yield self.augmentation(image, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = HsiDataloaderCutter(\n",
    "    path, preprocessing=preprocessing, \n",
    "    augmentation=test_augmentation, indices=test_indices,\n",
    "    cut_window=None\n",
    ")\n",
    "\n",
    "#dataset_train = HsiDataloaderCutter(\n",
    "#    path, preprocessing=preprocessing, \n",
    "#    augmentation=test_augmentation, indices=train_indices\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c16620",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1)\n",
    "\n",
    "#val_loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390daea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f101f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_loader = val_loader_test\n",
    "specter_list = []\n",
    "target_list = []\n",
    "\n",
    "for img_s, mask_s in tqdm(val_loader):\n",
    "    specter_list.append(img_s[0].numpy())\n",
    "    target_list.append(mask_s[0].numpy())\n",
    "    break\n",
    "len(specter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39915f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_s.shape, img_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdf68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 0\n",
    "indx_sp = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(specter_list[indx][indx_sp]), target_list[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d19726",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(target_list[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ff327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_test = dict([(str(i), 0) for i in range(17)])\n",
    "num_class2count_train = dict([(str(i), 0) for i in range(17)])\n",
    "\n",
    "num_class2count_pixels_test = dict([(str(i), 0) for i in range(17)])\n",
    "num_class2count_pixels_train = dict([(str(i), 0) for i in range(17)])\n",
    "\n",
    "# Test count\n",
    "for img_s, mask_s in tqdm(val_loader_test):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_test[str(n_c)] += 1\n",
    "\n",
    "# Train count\n",
    "for img_s, mask_s in tqdm(val_loader_train):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_train[str(n_c)] += 1\n",
    "\n",
    "# Test pixels\n",
    "for img_s, mask_s in tqdm(val_loader_test):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_pixels_test[str(n_c)] += torch.sum(mask_s == n_c).numpy()\n",
    "\n",
    "# Train pixels\n",
    "for img_s, mask_s in tqdm(val_loader_train):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_pixels_train[str(n_c)] += torch.sum(mask_s == n_c).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3800c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_train, index=[0]) / 324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04232aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_test, index=[0]) / 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_diff = dict()\n",
    "\n",
    "for k,v in num_class2count_test.items():\n",
    "    num_class2count_diff[str(k)] = v - num_class2count_train[k]\n",
    "    print(f'class={str(k).zfill(2)} num_test={str(v).zfill(2)} num_train={str(num_class2count_train[k]).zfill(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_diff, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_train, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_test, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_pixels_diff = dict()\n",
    "\n",
    "for k,v in num_class2count_pixels_test.items():\n",
    "    num_class2count_pixels_diff[str(k)] = v - num_class2count_pixels_train[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d75b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_diff, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8179b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03f5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e59b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cel = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b2bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5 * 17, requires_grad=True)\n",
    "target = torch.empty(3 * 5, dtype=torch.long).random_(17)\n",
    "input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feae9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = input.view(3 * 5, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cel(input, target.view(-1))\n",
    "output, output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e973dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cel(input, target)\n",
    "output, output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46133e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15caad6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b29669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
