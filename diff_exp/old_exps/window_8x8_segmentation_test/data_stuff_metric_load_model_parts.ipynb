{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from hsi_dataset_api import HsiDataset\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_INFO_PATH = '/home/rustam/hyperspecter_segmentation/danil_cave/kfolds_data/kfold0'\n",
    "PATH_DATA = '/raid/rustam/hyperspectral_dataset/new_cropped_hsi_data'\n",
    "\n",
    "test_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_test.npy')\n",
    "train_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_train.npy')\n",
    "\n",
    "pca_explained_variance = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaMean.npy')\n",
    "pca_components = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaComponents.npy')\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "\n",
    "def preprocessing(imgs, masks, cut_window=None):\n",
    "    with open(f'{PREFIX_INFO_PATH}/data_standartization_params_kfold0.json', 'r') as f:\n",
    "        data_standartization_params = json.load(f)\n",
    "    mean = data_standartization_params.get('means')\n",
    "    std = data_standartization_params.get('stds')\n",
    "    assert mean is not None and std is not None\n",
    "    def standartization(img):\n",
    "        return np.array((img - mean) / std, dtype=np.float32)\n",
    "    _images = [np.transpose(image, (1, 2, 0)) for image in imgs] #[pca_transformation(image) for image in imgs]\n",
    "    #_images = [standartization(image) for image in _images]\n",
    "    _masks = [\n",
    "        np.expand_dims(\n",
    "            cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "            ,0\n",
    "        ).astype(np.int64)\n",
    "        for mask in masks\n",
    "    ]\n",
    "    if cut_window is not None:\n",
    "        _masks = [mask2class(mask) for mask in _masks]\n",
    "    return _images, _masks\n",
    "\n",
    "\n",
    "def test_augmentation(image, mask, *args):\n",
    "    image = TF.to_tensor(image)\n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    \n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "from makitorch.data_tools.augmentation import DataAugmentator\n",
    "from makitorch.data_tools.augmentation import BaseDataAugmentor\n",
    "from makitorch.data_tools.preprocessing import BaseDataPreprocessor\n",
    "from makitorch.data_tools.preprocessing import DataPreprocessor\n",
    "\n",
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "from hsi_dataset_api import HsiDataset\n",
    "\n",
    "\n",
    "class HsiDataloaderCutter(torch.utils.data.IterableDataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            data_path: str,\n",
    "            preprocessing: Optional[Union[DataPreprocessor, Callable]] = BaseDataPreprocessor(),\n",
    "            augmentation: Optional[Union[DataAugmentator, Callable]] = BaseDataAugmentor(),\n",
    "            indices = None,\n",
    "            shuffle_data=False,\n",
    "            cut_window=(8, 8)\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.shuffle_data = shuffle_data\n",
    "        self.dataset = HsiDataset(data_path)\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.cut_window = cut_window\n",
    "        \n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        \n",
    "        for idx, data_point in enumerate(self.dataset.data_iterator(opened=True, shuffle=False)):\n",
    "            if indices is not None and idx not in indices:\n",
    "                continue\n",
    "            image, mask = data_point.hsi, data_point.mask\n",
    "            if cut_window is not None:\n",
    "                image_parts, mask_parts = self._cut_with_window(image, mask, cut_window)\n",
    "                self.images += image_parts\n",
    "                self.masks += mask_parts\n",
    "            else:\n",
    "                self.images.append(image)\n",
    "                self.masks.append(mask)\n",
    "        \n",
    "        if self.preprocessing is not None:\n",
    "            self.images, self.masks = self.preprocessing(self.images, self.masks, cut_window=cut_window)\n",
    "    \n",
    "    def _cut_with_window(self, image, mask, cut_window):\n",
    "        assert len(cut_window) == 2\n",
    "        h_win, w_win = cut_window\n",
    "        _, h, w = image.shape\n",
    "        h_parts = h // h_win\n",
    "        w_parts = w // w_win\n",
    "        if h % h_win != 0:\n",
    "            print(f\"{h % h_win} pixels will be dropped by h axis. Input shape={image.shape}\")\n",
    "\n",
    "        if w % w_win != 0:\n",
    "            print(f\"{w % w_win} pixels will be dropped by w axis. Input shape={image.shape}\")\n",
    "\n",
    "        image_parts_list = []\n",
    "        mask_parts_list = []\n",
    "\n",
    "        for h_i in range(h_parts):\n",
    "            for w_i in range(w_parts):\n",
    "                img_part = image[:, \n",
    "                    h_i * h_win: (h_i+1) * h_win, \n",
    "                    w_i * w_win: (w_i+1) * w_win\n",
    "                ]\n",
    "                mask_part = mask[\n",
    "                    h_i * h_win: (h_i+1) * h_win, \n",
    "                    w_i * w_win: (w_i+1) * w_win\n",
    "                ]\n",
    "\n",
    "                image_parts_list.append(img_part)\n",
    "                mask_parts_list.append(mask_part)\n",
    "        return image_parts_list, mask_parts_list\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle_data:\n",
    "            self.images, self.masks = shuffle(self.images, self.masks)\n",
    "        \n",
    "        for image, mask in zip(self.images, self.masks):\n",
    "            yield self.augmentation(image, mask, self.cut_window)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySuperNet3DLittleInput(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_f=17, out_f=17, *args):\n",
    "        super().__init__()\n",
    "        #self.bn_start = nn.BatchNorm3d(in_f)\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=(3, 3, 11), stride=(1, 1, 3), padding=(1, 1, 6))\n",
    "        # (N, 16, 8, 8, 80)\n",
    "        self.bn1 = nn.BatchNorm3d(16)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(16, 16, kernel_size=(3, 3, 5), stride=1, padding=(1, 1, 2))\n",
    "        # (N, 16, 8, 8, 80)\n",
    "        self.bn2 = nn.BatchNorm3d(16)\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(16, 16, kernel_size=(3, 3, 5), stride=1, padding=(1, 1, 2))\n",
    "        # (N, 16, 8, 8, 80)\n",
    "        self.bn3 = nn.BatchNorm3d(16)\n",
    "        self.act3 = nn.ReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv3d(16, 16, kernel_size=(2, 2, 5), stride=1, padding=(0, 0, 2))\n",
    "        # (N, 16, 7, 7, 80)\n",
    "        self.bn4 = nn.BatchNorm3d(16)\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        self.pooling = nn.AvgPool3d((2, 2, 3), stride=(2, 2, 3), padding=(0, 0, 1))\n",
    "        # (N, 16, 3, 3, 27)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(16 * 3 * 3 * 27, 17, bias=False)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # (N, 237, 8, 8) -> (N, 1, 8, 8, 237)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.act3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.act4(x)\n",
    "\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(x.shape[0], -1) # (N, ...)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71735d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MySuperNet3DLittleInput(17, 17)\n",
    "_ = net(torch.randn(1, 237, 8, 8)).shape\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NnModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self, model, loss,\n",
    "            T_0=10, T_mult=2, experiment=None, enable_image_logging=True):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.experiment = experiment\n",
    "        self.enable_image_logging = enable_image_logging\n",
    "        #self.weight_contraint_function = WeightConstraint()\n",
    "\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "\n",
    "    def _custom_histogram_adder(self):\n",
    "        for name,params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name,params,self.current_epoch)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(\n",
    "            self.parameters(), lr=1e-3\n",
    "        )\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, \n",
    "            T_0=self.T_0, T_mult=self.T_mult, eta_min=0\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        img, mask = train_batch\n",
    "        preds = self.model(img) # (N, C)\n",
    "        loss = self.loss(preds, mask) # (N,)\n",
    "        self.log('train_loss', loss)\n",
    "        if self.experiment is not None:\n",
    "            self.experiment.log_metric(\"train_loss\", loss, epoch=self.current_epoch, step=self.global_step)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return batch\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        print('Size epoch end input: ', len(outputs))\n",
    "        \n",
    "        pred_tensor, target_tensor = collect_prediction_and_target(outputs, self.model)\n",
    "        target_one_hotted_tensor = list_target_to_onehot(target_tensor)\n",
    "        dice_loss_val = dice_loss(pred_tensor, target_one_hotted_tensor, dim=[0, 2, 3], use_softmax=True, softmax_dim=1)\n",
    "        metric, pred_as_mask_list = calculate_iou(pred_tensor, target_tensor)\n",
    "        \n",
    "        for batch_idx, (metric_s, target_s, pred_s) in enumerate(zip(metric, target_tensor, pred_as_mask_list)):\n",
    "            if self.enable_image_logging:\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "                sns.heatmap(pred_s, ax=ax1, vmin=0, vmax=17)\n",
    "                sns.heatmap(target_s.cpu().detach().numpy(), ax=ax2, vmin=0, vmax=17)\n",
    "                fig.savefig('temp_fig.png')\n",
    "                plt.close(fig)\n",
    "\n",
    "    #             trainer.logger.experiment.log_histogram_3d(\n",
    "    #                 self.model.features_selection.weight.detach().cpu().numpy(),\n",
    "    #                 name='band-selection layer',\n",
    "    #                 step=self.global_step\n",
    "    #             )\n",
    "                if self.experiment is not None:\n",
    "                    # For Comet logger\n",
    "                    self.experiment.log_image(\n",
    "                        'temp_fig.png', name=f'{batch_idx}', \n",
    "                        overwrite=False, step=self.global_step\n",
    "                    )\n",
    "            \n",
    "            d = {f'iou_{i}': iou for i, iou in enumerate(metric_s)}\n",
    "            \n",
    "            if self.experiment is not None:\n",
    "                self.experiment.log_metrics(d, epoch=self.current_epoch)\n",
    "            else:\n",
    "                print(d)\n",
    "        if self.experiment is not None:\n",
    "            # Add confuse matrix\n",
    "            self.experiment.log_confusion_matrix(\n",
    "                target_tensor.cpu().detach().numpy().reshape(-1), \n",
    "                np.asarray(pred_as_mask_list).reshape(-1)\n",
    "            )\n",
    "            \n",
    "        mean_per_class_metric, mean_metric = clear_metric_calculation(metric, target_tensor, pred_tensor)\n",
    "        mean_dice_loss_per_class_dict = {\n",
    "            f\"mean_dice_loss_per_class_{i}\": torch.tensor(d_l, dtype=torch.float)\n",
    "            for i, d_l in enumerate(dice_loss_val)\n",
    "        }\n",
    "        mean_dice_loss_dict = {\n",
    "            f\"mean_dice_loss\": torch.tensor(dice_loss_val.mean(), dtype=torch.float)\n",
    "        }\n",
    "        mean_iou_class_dict = {\n",
    "            f\"mean_iou_class_{i}\": torch.tensor(iou, dtype=torch.float)\n",
    "            for i, iou in enumerate(mean_per_class_metric)\n",
    "        }\n",
    "        mean_iou_dict = {\n",
    "            \"mean_iou\": torch.tensor(mean_metric, dtype=torch.float),\n",
    "        }\n",
    "        \n",
    "        # Log this metric in order to save checkpoint of experements\n",
    "        self.log_dict(mean_iou_dict)\n",
    "        \n",
    "        if self.experiment is not None:\n",
    "        \n",
    "            self.experiment.log_metrics(\n",
    "                mean_dice_loss_per_class_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "\n",
    "            self.experiment.log_metrics(\n",
    "                mean_dice_loss_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "\n",
    "            self.experiment.log_metrics(\n",
    "                mean_iou_class_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "\n",
    "            self.experiment.log_metrics(\n",
    "                mean_iou_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "        else:\n",
    "            print(mean_dice_loss_per_class_dict)\n",
    "            print(mean_dice_loss_dict)\n",
    "            print(mean_iou_class_dict)\n",
    "            print(mean_iou_dict)\n",
    "            print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c42b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "w_sorted = sorted(glob.glob('pytorch_li_logs/(run=1)MySuperNet3DLittleInput | _LrCosine W weight decay lower_arch_50ep_Wo full PCA._RustamPreprocess(k=1)_CEcosine(t_0=2,t_mul=1) | arch_type=MySuperNet3DLittleInput/*'), \n",
    "       key=lambda x: -float(x.split('/')[-1].split('-')[-1][9:13])\n",
    ")\n",
    "\n",
    "pick_best_one = w_sorted[0]\n",
    "w_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.conv1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.conv1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NnModel.load_from_checkpoint(\n",
    "    pick_best_one,\n",
    "    loss=None, model=net\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1962fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model.model\n",
    "net.to(device=device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = HsiDataloaderCutter(\n",
    "    PATH_DATA, preprocessing=preprocessing, \n",
    "    augmentation=test_augmentation, indices=test_indices,\n",
    "    cut_window=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c16620",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390daea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bce159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_prediction_and_target(eval_loader, model, cut_window=(8, 8), image_shape=(512, 512), num_classes=17):\n",
    "    target_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    for in_data_x, val_data in tqdm(eval_loader):\n",
    "        batch_size = in_data_x.shape[0]\n",
    "        pred_mask = torch.zeros(\n",
    "            (batch_size, num_classes, image_shape[0], image_shape[1]),\n",
    "            dtype=in_data_x.dtype, device=in_data_x.device\n",
    "        )\n",
    "        # Take prediction from each window\n",
    "        for w_i in range(image_shape[1] // cut_window[1]):\n",
    "            for h_i in range(image_shape[0] // cut_window[0]):\n",
    "                img_part = in_data_x[:, :, \n",
    "                    h_i * cut_window[0]: (h_i+1) * cut_window[0],\n",
    "                    w_i * cut_window[1]: (w_i+1) * cut_window[1]\n",
    "                ]\n",
    "                img_part = img_part.to(device=device)\n",
    "                with torch.no_grad():\n",
    "                    pred = model(img_part.to(device=device)).cpu() # (N, num_classes) -> (N, num_classes, 1, 1)\n",
    "                _ = img_part.cpu()\n",
    "                pred = pred.unsqueeze(dim=-1).unsqueeze(dim=-1)\n",
    "                pred_mask[:, :,\n",
    "                    h_i * cut_window[0]: (h_i+1) * cut_window[0],\n",
    "                    w_i * cut_window[1]: (w_i+1) * cut_window[1]\n",
    "                ] = pred\n",
    "        \n",
    "        target_list.append(val_data)\n",
    "        pred_list.append(pred_mask)\n",
    "    return (torch.cat(pred_list, dim=0), \n",
    "            torch.cat(target_list, dim=0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676b86e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_tensor, target_tensor = collect_prediction_and_target(val_loader, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ca87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'pred_tensor.shape={pred_tensor.shape}')\n",
    "print(f'target_tensor.shape={target_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f101f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_softmax = nn.functional.softmax(pred_tensor, dim=1)\n",
    "pred_np = pred_softmax.cpu().detach().numpy()\n",
    "pred_np = np.transpose(pred_np, [0, 2, 3, 1])\n",
    "pred_np = np.argmax(pred_np, axis=-1)\n",
    "target_np = torch.squeeze(target_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e86d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np.shape, target_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdf68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx=22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c8b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(pred_np[indx], vmax=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d19726",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(target_np[indx], vmax=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0912ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(pred_np).reshape(-1),\n",
    "    np.asarray(target_np).reshape(-1), \n",
    "    average='macro'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270ff41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    np.asarray(pred_np).reshape(-1),\n",
    "    np.asarray(target_np).reshape(-1), \n",
    "    average='weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.asarray(pred_np).reshape(-1) == np.asarray(target_np).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ed3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
