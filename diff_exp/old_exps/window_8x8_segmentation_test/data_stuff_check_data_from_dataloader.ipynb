{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from hsi_dataset_api import HsiDataset\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLossCustom(nn.Module):\n",
    "    \"\"\"\n",
    "    copy from: https://github.com/Hsuxu/Loss_ToolBox-PyTorch/blob/master/FocalLoss/FocalLoss.py\n",
    "    This is a implementation of Focal Loss with smooth label cross entropy supported which is proposed in\n",
    "    'Focal Loss for Dense Object Detection. (https://arxiv.org/abs/1708.02002)'\n",
    "        Focal_Loss= -1*alpha*(1-pt)*log(pt)\n",
    "    :param num_class:\n",
    "    :param alpha: (tensor) 3D or 4D the scalar factor for this criterion\n",
    "    :param gamma: (float,double) gamma > 0 reduces the relative loss for well-classified examples (p>0.5) putting more\n",
    "                    focus on hard misclassified example\n",
    "    :param smooth: (float,double) smooth value when cross entropy\n",
    "    :param balance_index: (int) balance class index, should be specific when alpha is float\n",
    "    :param size_average: (bool, optional) By default, the losses are averaged over each loss element in the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=None, gamma=5.5, balance_index=2, smooth=1e-5, size_average=False):\n",
    "        super(FocalLossCustom, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.balance_index = balance_index\n",
    "        self.smooth = smooth\n",
    "        self.size_average = size_average\n",
    "        self.cel = nn.CrossEntropyLoss(reduction='none')\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        if self.smooth is not None:\n",
    "            if self.smooth < 0 or self.smooth > 1.0:\n",
    "                raise ValueError('smooth value should be in [0,1]')\n",
    "\n",
    "    def forward(self, logit, target):\n",
    "        num_class = logit.shape[1]\n",
    "\n",
    "        if logit.dim() > 2:\n",
    "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "            logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "            # N,C,m -> N,m,C\n",
    "            logit = logit.permute(0, 2, 1).contiguous()\n",
    "            # N,m,C -> N,m*C\n",
    "            logit = logit.view(-1, logit.size(-1))\n",
    "        target = torch.squeeze(target, 1)\n",
    "        target = target.view(-1, 1)\n",
    "        \n",
    "        ce_loss = self.cel(logit, target.view(-1))\n",
    "        train_conf = self.softmax(logit)\n",
    "        \n",
    "        idx = target.cpu().long()\n",
    "        one_hot_labels  = torch.FloatTensor(target.size(0), num_class).zero_()\n",
    "        one_hot_labels  = one_hot_labels.scatter_(1, idx, 1)\n",
    "        if one_hot_labels.device != logit.device:\n",
    "            one_hot_labels = one_hot_labels.to(logit.device)\n",
    "        \n",
    "        filtered_conf = train_conf * one_hot_labels\n",
    "        sparce_conf, _ = torch.max(filtered_conf, dim=-1)\n",
    "        loss = torch.pow((torch.ones_like(sparce_conf) - sparce_conf), self.gamma) * ce_loss\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        if not self.size_average:\n",
    "            # Norm by positive\n",
    "            num_positive = torch.sum(target != self.balance_index)\n",
    "            loss = loss.sum() / (num_positive + 1e-10)\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'focal_loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = FocalLossCustom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_INFO_PATH = '/home/rustam/hyperspecter_segmentation/danil_cave/kfolds_data/kfold0'\n",
    "\n",
    "\n",
    "pca_explained_variance = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaMean.npy')\n",
    "pca_components = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaComponents.npy')\n",
    "test_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_test.npy')\n",
    "train_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_train.npy')\n",
    "\n",
    "path = '/raid/rustam/hyperspectral_dataset/new_cropped_hsi_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transformation(x):\n",
    "    x_t = np.reshape(x, (x.shape[0], -1)) # (C, H, W) -> (C, H * W)\n",
    "    x_t = np.swapaxes(x_t, 0, 1) # (C, H * W) -> (H * W, C)\n",
    "    x_t = x_t - pca_mean\n",
    "    x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "    return np.reshape(x_t, (x.shape[1], x.shape[2], pca_components.shape[0])).astype(np.float32) # (H, W, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_augmentation(image, mask, *args):\n",
    "    image = TF.to_tensor(image)\n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    \n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def mask2class(mask):\n",
    "    # Calculate which class have more pixel count\n",
    "    max_value = -1\n",
    "    pixel_count = -1\n",
    "    for class_indx in np.unique(mask):\n",
    "        pix_count_s = np.sum(mask == class_indx)\n",
    "        if pix_count_s > pixel_count:\n",
    "            max_value = class_indx\n",
    "            pixel_count = pix_count_s\n",
    "    assert max_value != -1\n",
    "    return np.array([max_value], dtype=np.int64) \n",
    "\n",
    "\n",
    "def preprocessing(imgs, masks, map_mask_to_class=False):\n",
    "    with open(f'{PREFIX_INFO_PATH}/data_standartization_params_kfold0.json', 'r') as f:\n",
    "        data_standartization_params = json.load(f)\n",
    "    mean = data_standartization_params.get('means')\n",
    "    std = data_standartization_params.get('stds')\n",
    "    assert mean is not None and std is not None\n",
    "    def standartization(img):\n",
    "        return np.array((img - mean) / std, dtype=np.float32)\n",
    "    _images = [np.transpose(image, (1, 2, 0)) for image in imgs] #[pca_transformation(image) for image in imgs]\n",
    "    #_images = [standartization(image) for image in _images]\n",
    "    _masks = [\n",
    "        np.expand_dims(\n",
    "            cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "            ,0\n",
    "        ).astype(np.int64)\n",
    "        for mask in masks\n",
    "    ]\n",
    "    if map_mask_to_class:\n",
    "        _masks = [mask2class(mask) for mask in _masks]\n",
    "    return _images, _masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7925dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from makitorch.data_tools.augmentation import DataAugmentator\n",
    "from makitorch.data_tools.augmentation import BaseDataAugmentor\n",
    "from makitorch.data_tools.preprocessing import BaseDataPreprocessor\n",
    "from makitorch.data_tools.preprocessing import DataPreprocessor\n",
    "\n",
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "from hsi_dataset_api import HsiDataset\n",
    "\n",
    "\n",
    "class HsiDataloaderCutter(torch.utils.data.IterableDataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            data_path: str,\n",
    "            preprocessing: Optional[Union[DataPreprocessor, Callable]] = BaseDataPreprocessor(),\n",
    "            augmentation: Optional[Union[DataAugmentator, Callable]] = BaseDataAugmentor(),\n",
    "            indices = None,\n",
    "            shuffle_data=False,\n",
    "            cut_window=(8, 8),\n",
    "            map_mask_to_class=False,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.shuffle_data = shuffle_data\n",
    "        self.dataset = HsiDataset(data_path)\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.cut_window = cut_window\n",
    "        \n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        \n",
    "        for idx, data_point in enumerate(self.dataset.data_iterator(opened=True, shuffle=False)):\n",
    "            if indices is not None and idx not in indices:\n",
    "                continue\n",
    "            image, mask = data_point.hsi, data_point.mask\n",
    "            if cut_window is not None:\n",
    "                image_parts, mask_parts = self._cut_with_window(image, mask, cut_window)\n",
    "                self.images += image_parts\n",
    "                self.masks += mask_parts\n",
    "            else:\n",
    "                self.images.append(image)\n",
    "                self.masks.append(mask)\n",
    "        \n",
    "        if self.preprocessing is not None:\n",
    "            self.images, self.masks = self.preprocessing(\n",
    "                self.images, self.masks, map_mask_to_class=map_mask_to_class\n",
    "            )\n",
    "    \n",
    "    def _cut_with_window(self, image, mask, cut_window):\n",
    "        assert len(cut_window) == 2\n",
    "        h_win, w_win = cut_window\n",
    "        _, h, w = image.shape\n",
    "        h_parts = h // h_win\n",
    "        w_parts = w // w_win\n",
    "        if h % h_win != 0:\n",
    "            print(f\"{h % h_win} pixels will be dropped by h axis. Input shape={image.shape}\")\n",
    "\n",
    "        if w % w_win != 0:\n",
    "            print(f\"{w % w_win} pixels will be dropped by w axis. Input shape={image.shape}\")\n",
    "\n",
    "        image_parts_list = []\n",
    "        mask_parts_list = []\n",
    "\n",
    "        for h_i in range(h_parts):\n",
    "            for w_i in range(w_parts):\n",
    "                img_part = image[:, \n",
    "                    h_i * h_win: (h_i+1) * h_win, \n",
    "                    w_i * w_win: (w_i+1) * w_win\n",
    "                ]\n",
    "                mask_part = mask[\n",
    "                    h_i * h_win: (h_i+1) * h_win, \n",
    "                    w_i * w_win: (w_i+1) * w_win\n",
    "                ]\n",
    "\n",
    "                image_parts_list.append(img_part)\n",
    "                mask_parts_list.append(mask_part)\n",
    "        return image_parts_list, mask_parts_list\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle_data:\n",
    "            self.images, self.masks = shuffle(self.images, self.masks)\n",
    "        \n",
    "        for image, mask in zip(self.images, self.masks):\n",
    "            yield self.augmentation(image, mask, self.cut_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = HsiDataloaderCutter(\n",
    "    path, preprocessing=preprocessing, \n",
    "    augmentation=test_augmentation, indices=test_indices,\n",
    "    cut_window=(8, 8), map_mask_to_class=False\n",
    ")\n",
    "\n",
    "#dataset_train = HsiDataloaderCutter(\n",
    "#    path, preprocessing=preprocessing, \n",
    "#    augmentation=test_augmentation, indices=train_indices\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c16620",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1)\n",
    "\n",
    "#val_loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390daea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f101f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_loader = val_loader_test\n",
    "specter_list = []\n",
    "target_list = []\n",
    "\n",
    "for i, (img_s, mask_s) in enumerate(tqdm(val_loader)):\n",
    "    specter_list.append(img_s[0].numpy())\n",
    "    target_list.append(mask_s[0].numpy())\n",
    "    if len(np.unique(target_list[-1])) > 1:\n",
    "        print(i)\n",
    "    if i == 1000:\n",
    "        break\n",
    "len(specter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39915f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_s.shape, img_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdf68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 955\n",
    "indx_sp = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(specter_list[indx][indx_sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d19726",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(target_list[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ff327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_test = dict([(str(i), 0) for i in range(17)])\n",
    "num_class2count_train = dict([(str(i), 0) for i in range(17)])\n",
    "\n",
    "num_class2count_pixels_test = dict([(str(i), 0) for i in range(17)])\n",
    "num_class2count_pixels_train = dict([(str(i), 0) for i in range(17)])\n",
    "\n",
    "# Test count\n",
    "for img_s, mask_s in tqdm(val_loader_test):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_test[str(n_c)] += 1\n",
    "\n",
    "# Train count\n",
    "for img_s, mask_s in tqdm(val_loader_train):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_train[str(n_c)] += 1\n",
    "\n",
    "# Test pixels\n",
    "for img_s, mask_s in tqdm(val_loader_test):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_pixels_test[str(n_c)] += torch.sum(mask_s == n_c).numpy()\n",
    "\n",
    "# Train pixels\n",
    "for img_s, mask_s in tqdm(val_loader_train):\n",
    "    for n_c in np.unique(mask_s):\n",
    "        num_class2count_pixels_train[str(n_c)] += torch.sum(mask_s == n_c).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3800c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_train, index=[0]) / 324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04232aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_test, index=[0]) / 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_diff = dict()\n",
    "\n",
    "for k,v in num_class2count_test.items():\n",
    "    num_class2count_diff[str(k)] = v - num_class2count_train[k]\n",
    "    print(f'class={str(k).zfill(2)} num_test={str(v).zfill(2)} num_train={str(num_class2count_train[k]).zfill(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_diff, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_train, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_test, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class2count_pixels_diff = dict()\n",
    "\n",
    "for k,v in num_class2count_pixels_test.items():\n",
    "    num_class2count_pixels_diff[str(k)] = v - num_class2count_pixels_train[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d75b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame(num_class2count_pixels_diff, index=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8179b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03f5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e59b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cel = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b2bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5 * 17, requires_grad=True)\n",
    "target = torch.empty(3 * 5, dtype=torch.long).random_(17)\n",
    "input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feae9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = input.view(3 * 5, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cel(input, target.view(-1))\n",
    "output, output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e973dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cel(input, target)\n",
    "output, output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46133e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15caad6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b29669",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e263045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
