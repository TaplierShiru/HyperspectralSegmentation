{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e042c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# %%\n",
    "\n",
    "import os\n",
    "\n",
    "GPU_ID = \"1\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/makitorch')\n",
    "sys.path.append('/home/rustam/hyperspecter_segmentation/')\n",
    "\n",
    "PREFIX_INFO_PATH = '/home/rustam/hyperspecter_segmentation/danil_cave/kfolds_data/kfold0'\n",
    "PATH_DATA = '/raid/rustam/hyperspectral_dataset/new_cropped_hsi_data'\n",
    "\n",
    "\n",
    "from multiprocessing.dummy import Pool\n",
    "import copy\n",
    "import glob\n",
    "from makitorch import *\n",
    "import math\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import comet_ml\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "from Losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from makitorch.architectures.U2Net import U2Net\n",
    "\n",
    "from hsi_dataset_api import HsiDataset\n",
    "\n",
    "from makitorch.dataloaders.HsiDataloader import HsiDataloader\n",
    "from makitorch.architectures.Unet import Unet, UnetWithFeatureSelection\n",
    "from makitorch.loss import muti_bce_loss_fusion\n",
    "from sklearn.metrics import jaccard_score\n",
    "np.set_printoptions(suppress=True)\n",
    "torch.backends.cudnn.benchmark = True # Speed up\n",
    "\n",
    "\n",
    "from makitorch.data_tools.augmentation import DataAugmentator\n",
    "from makitorch.data_tools.augmentation import BaseDataAugmentor\n",
    "from makitorch.data_tools.preprocessing import BaseDataPreprocessor\n",
    "from makitorch.data_tools.preprocessing import DataPreprocessor\n",
    "\n",
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "from hsi_dataset_api import HsiDataset\n",
    "\n",
    "\n",
    "@nb.njit\n",
    "def cut_into_parts(\n",
    "        image: np.ndarray, mask: np.ndarray, \n",
    "        shift_h: int, shift_w: int):\n",
    "    image_parts_list = []\n",
    "    mask_parts_list = []\n",
    "\n",
    "    for h_i in range(shift_h, mask.shape[0]-shift_h):\n",
    "        for w_i in range(shift_w, mask.shape[1]-shift_w):\n",
    "            img_part = image[:, \n",
    "                (h_i - shift_h): (h_i + shift_h + 1), \n",
    "                (w_i - shift_w): (w_i + shift_w + 1)\n",
    "            ]\n",
    "            mask_part = mask[\n",
    "                (h_i - shift_h): (h_i + shift_h + 1), \n",
    "                (w_i - shift_w): (w_i + shift_w + 1)\n",
    "            ]\n",
    "\n",
    "            image_parts_list.append(img_part)\n",
    "            mask_parts_list.append(mask_part)\n",
    "    return image_parts_list, mask_parts_list\n",
    "\n",
    "\n",
    "\n",
    "class ShmData:\n",
    "\n",
    "    def __init__(self, shm_name, shape, dtype):\n",
    "        self.shm_name = shm_name\n",
    "        self.shape = shape\n",
    "        self.dtype = dtype\n",
    "\n",
    "\n",
    "class DatasetCreator:\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            data_path: str,\n",
    "            indices = None,\n",
    "            cut_window=(8, 8),\n",
    "            map_mask_to_class=False,\n",
    "            shuffle_then_prepared=False):\n",
    "        self.dataset = HsiDataset(data_path)\n",
    "        self.cut_window = cut_window\n",
    "        self.map_mask_to_class = map_mask_to_class\n",
    "        \n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        self._shm_imgs = None\n",
    "        self._shm_masks = None\n",
    "\n",
    "        for idx, data_point in tqdm(enumerate(self.dataset.data_iterator(opened=True, shuffle=False))):\n",
    "            if indices is not None and idx not in indices:\n",
    "                continue\n",
    "            image, mask = data_point.hsi, data_point.mask\n",
    "            if cut_window is not None:\n",
    "                image_parts, mask_parts = self._cut_with_window(image, mask, cut_window)\n",
    "                self.images += image_parts\n",
    "                self.masks += mask_parts\n",
    "            else:\n",
    "                self.images.append(image)\n",
    "                self.masks.append(mask)\n",
    "        if shuffle_then_prepared:\n",
    "            self.images, self.masks = shuffle(self.images, self.masks)\n",
    "                    \n",
    "    \n",
    "    def _cut_with_window(self, image, mask, cut_window):\n",
    "        assert len(cut_window) == 2\n",
    "        h_win, w_win = cut_window\n",
    "        _, h, w = image.shape\n",
    "        # Append values to mask\n",
    "        mask_shape = list(mask.shape)\n",
    "        # Calculate additional padding values\n",
    "        shift_w, shift_h = (\n",
    "            (w_win - 1)//2, \n",
    "            (h_win - 1)//2\n",
    "        )\n",
    "        if shift_w == 0 and shift_h == 0:\n",
    "            padding_img = image\n",
    "            padding_mask = mask\n",
    "        else:\n",
    "            # Multiply on 2\n",
    "            mask_shape[0] += shift_h * 2\n",
    "            mask_shape[1] += shift_w * 2\n",
    "            # Create padding mask and copy original data\n",
    "            padding_mask = np.zeros(mask_shape, dtype=mask.dtype)\n",
    "            padding_mask[shift_h:-shift_h, shift_w:-shift_w] = mask\n",
    "            # Create padding img and copy original data\n",
    "            img_shape = list(image.shape)\n",
    "            img_shape[1] += shift_h * 2\n",
    "            img_shape[2] += shift_w * 2\n",
    "            padding_img = np.zeros(img_shape, dtype=image.dtype)\n",
    "            padding_img[:, shift_h:-shift_h, shift_w:-shift_w] = image\n",
    "        return cut_into_parts(\n",
    "            image=padding_img, mask=padding_mask,\n",
    "            shift_w=shift_w, shift_h=shift_h\n",
    "        )\n",
    "\n",
    "\n",
    "class HsiDataloaderCutter(torch.utils.data.IterableDataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            images, masks,\n",
    "            batch_size,\n",
    "            augmentation: Optional[Union[DataAugmentator, Callable]] = BaseDataAugmentor(),\n",
    "            preprocessing: Optional[Union[DataPreprocessor, Callable]] = None,\n",
    "            shuffle_data=False,\n",
    "            cut_window=(8, 8),\n",
    "            map_mask_to_class=False,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.shuffle_data = shuffle_data\n",
    "        self.augmentation = augmentation\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocessing = preprocessing\n",
    "        if cut_window is not None and cut_window[0] == 1 and cut_window[1] == 1:\n",
    "            self.ignore_image_augs = True\n",
    "        else:\n",
    "            self.ignore_image_augs = False\n",
    "        self.cut_window = cut_window\n",
    "        self.map_mask_to_class = map_mask_to_class\n",
    "\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "\n",
    "    def __iter__(self):\n",
    "        assert self.images is not None and self.masks is not None\n",
    "        if self.shuffle_data:\n",
    "            self.images, self.masks = shuffle(self.images, self.masks)\n",
    "        \n",
    "        batch_parts = len(self.images) // self.batch_size\n",
    "\n",
    "        for i in range(batch_parts):\n",
    "            image_batch = self.images[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "            mask_batch = self.masks[i * self.batch_size: (i + 1) * self.batch_size] \n",
    "\n",
    "            image_batch, mask_batch = self.preprocessing(\n",
    "                image_batch, mask_batch,\n",
    "                map_mask_to_class=self.map_mask_to_class\n",
    "            )\n",
    "            yield self.augmentation(\n",
    "                image_batch, mask_batch, \n",
    "                map_mask_to_class=self.map_mask_to_class,\n",
    "                ignore_image_augs=self.ignore_image_augs\n",
    "            )\n",
    "\n",
    "\n",
    "def clear_metric_calculation(final_metric, target_t, pred_t, num_classes=17, using_pred=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    final_metric: torch.Tensor\n",
    "        Tensor with shape (N, C)\n",
    "    target_t: torch.Tensor or list\n",
    "        Tensor with shape (N, 1, H, W)\n",
    "    pred_t: torch.Tensor or list\n",
    "        Tensor with shape (N, 1, H, W)\n",
    "    \n",
    "    \"\"\"\n",
    "    # For each image\n",
    "    final_metric_dict = dict([\n",
    "        (str(i), []) for i in range(num_classes)\n",
    "    ])\n",
    "    for metric_s, target_t_s, pred_t_s in zip(final_metric, target_t, pred_t):\n",
    "        unique_indx_target = torch.unique(target_t_s.long())\n",
    "        unique_indx_pred = None\n",
    "        if using_pred:\n",
    "            if isinstance(pred_t_s, np.ndarray):\n",
    "                pred_t_s = torch.from_numpy(pred_t_s)\n",
    "            unique_indx_pred = torch.unique(pred_t_s.long())\n",
    "        for i in range(num_classes):\n",
    "            if i in unique_indx_target or \\\n",
    "                    (unique_indx_pred is not None and i in unique_indx_pred):\n",
    "                final_metric_dict[str(i)].append(metric_s[i])\n",
    "    \n",
    "    mean_per_class_metric = [\n",
    "        sum(final_metric_dict[str(i)]) / len(final_metric_dict[str(i)])\n",
    "        if len(final_metric_dict[str(i)]) != 0\n",
    "        else 0.0\n",
    "        for i in range(num_classes)\n",
    "    ] \n",
    "    mean_metric = sum(mean_per_class_metric) / len(mean_per_class_metric)\n",
    "    return mean_per_class_metric, mean_metric\n",
    "\n",
    "\n",
    "def cut_into_parts_model_input(\n",
    "        image: torch.tensor,\n",
    "        shift_w: int, shift_h: int):\n",
    "    image_parts_list = []\n",
    "    for h_i in range(shift_h, image.shape[2]-shift_h):\n",
    "        for w_i in range(shift_w, image.shape[3]-shift_w):\n",
    "            img_part = image[:, :,\n",
    "                (h_i - shift_h): (h_i + shift_h + 1), \n",
    "                (w_i - shift_w): (w_i + shift_w + 1)\n",
    "            ]\n",
    "            image_parts_list.append(img_part)\n",
    "    return image_parts_list\n",
    "\n",
    "\n",
    "def merge_parts_into_single_mask(preds, shape):\n",
    "    pred_mask = torch.zeros(\n",
    "        shape,\n",
    "        dtype=preds.dtype, device=preds.device\n",
    "    )\n",
    "    counter = 0\n",
    "\n",
    "    for h_i in range(shape[2]):\n",
    "        for w_i in range(shape[3]):\n",
    "            # Map preds, from (17,) -> (17, 1, 1) - aka pixel result\n",
    "            pred_mask[\n",
    "                :, :, \n",
    "                h_i:(h_i + 1), w_i:(w_i + 1)\n",
    "            ] = preds[counter].unsqueeze(dim=-1).unsqueeze(dim=-1)\n",
    "            counter += 1\n",
    "    return pred_mask\n",
    "\n",
    "\n",
    "def collect_prediction_and_target(\n",
    "        eval_loader, model, cut_window=(8, 8), \n",
    "        image_shape=(512, 512), num_classes=17,\n",
    "        divided_batch=512):\n",
    "    target_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    for in_data_x, val_data in iter(eval_loader):\n",
    "        batch_size = in_data_x.shape[0]\n",
    "        # We will cut image into peases and stack it into single BIG batch\n",
    "        h_win, w_win = cut_window\n",
    "        # Calculate additional padding values\n",
    "        shift_w, shift_h = (\n",
    "            (w_win - 1)//2, \n",
    "            (h_win - 1)//2\n",
    "        )\n",
    "        if shift_w == 0 and shift_h == 0:\n",
    "            padding_img = in_data_x\n",
    "        else:\n",
    "            # Create padding img and copy original data\n",
    "            img_shape = list(in_data_x.shape)\n",
    "            img_shape[2] += shift_h * 2\n",
    "            img_shape[3] += shift_w * 2\n",
    "            padding_img = torch.zeros(img_shape, dtype=in_data_x.dtype, device=in_data_x.device)\n",
    "            padding_img[:, :, shift_h:-shift_h, shift_w:-shift_w] = in_data_x\n",
    "            padding_img = padding_img\n",
    "        in_data_x_parts_list = cut_into_parts_model_input(\n",
    "            padding_img, \n",
    "            shift_w=shift_w, shift_h=shift_h\n",
    "        )\n",
    "        in_data_x_batch = torch.cat(in_data_x_parts_list, dim=0) # (image_shape[0] * image_shape[1], 17, 8, 8)\n",
    "        part_divided = len(in_data_x_batch) // divided_batch\n",
    "        pred_batch_list = []\n",
    "        for b_i in range(part_divided):\n",
    "            if b_i == (part_divided - 1):\n",
    "                # last\n",
    "                single_batch = in_data_x_batch[b_i * divided_batch:]\n",
    "            else:\n",
    "                single_batch = in_data_x_batch[b_i * divided_batch: (b_i+1) * divided_batch]\n",
    "            # Make predictions\n",
    "            preds = model(single_batch) # (divided_batch, num_classes)\n",
    "            pred_batch_list.append(preds)\n",
    "        preds = torch.cat(pred_batch_list, dim=0) \n",
    "        # Create full image again from peases\n",
    "        pred_mask = merge_parts_into_single_mask(\n",
    "            preds=preds, \n",
    "            shape=(batch_size, num_classes, image_shape[0], image_shape[1]), \n",
    "        )\n",
    "        target_list.append(val_data)\n",
    "        pred_list.append(pred_mask)\n",
    "    return (torch.cat(pred_list, dim=0), \n",
    "            torch.cat(target_list, dim=0)\n",
    "    )\n",
    "        \n",
    "\n",
    "def calculate_iou(pred_list, target_list, num_classes=17):\n",
    "    res_list = []\n",
    "    pred_as_mask_list = []\n",
    "    \n",
    "    for preds, target in zip(pred_list, target_list):\n",
    "        # preds - (num_classes, H, W)\n",
    "        preds = preds.detach()\n",
    "        # target - (H, W)\n",
    "        target = target.detach()\n",
    "\n",
    "        preds = nn.functional.softmax(preds, dim=0)\n",
    "        preds = torch.argmax(preds, dim=0)\n",
    "        pred_as_mask_list.append(preds)\n",
    "        \n",
    "        preds_one_hoted = torch.nn.functional.one_hot(preds, num_classes).view(-1, num_classes).cpu()\n",
    "        target_one_hoted = torch.nn.functional.one_hot(target, num_classes).view(-1, num_classes).cpu()\n",
    "        res = jaccard_score(target_one_hoted, preds_one_hoted, average=None, zero_division=1)\n",
    "        res_list.append(\n",
    "            res\n",
    "        )\n",
    "    \n",
    "    res_np = np.stack(res_list)\n",
    "    #res_np = res_np.mean(axis=0)\n",
    "    return res_np, pred_as_mask_list\n",
    "\n",
    "\n",
    "def dice_loss(preds, ground_truth, eps=1e-5, dim=None, use_softmax=False, softmax_dim=1):\n",
    "    \"\"\"\n",
    "    Computes Dice loss according to the formula from:\n",
    "    V-Net: Fully Convolutional Neural Networks forVolumetric Medical Image Segmentation\n",
    "    Link to the paper: http://campar.in.tum.de/pub/milletari2016Vnet/milletari2016Vnet.pdf\n",
    "    Parameters\n",
    "    ----------\n",
    "    preds : tf.Tensor\n",
    "        Predicted probabilities.\n",
    "    ground_truth : tf.Tensor\n",
    "        Ground truth labels.\n",
    "    eps : float\n",
    "        Used to prevent division by zero in the Dice denominator.\n",
    "    axes : list\n",
    "        Defines which axes the dice value will be computed on. The computed dice values will be averaged\n",
    "        along the remaining axes. If None, Dice is computed on an entire batch.\n",
    "    Returns\n",
    "    -------\n",
    "    tf.Tensor\n",
    "        Scalar dice loss tensor.\n",
    "    \"\"\"\n",
    "    ground_truth = ground_truth.float().to(device=preds.device)\n",
    "    \n",
    "    if use_softmax:\n",
    "        preds = nn.functional.softmax(preds, dim=softmax_dim)\n",
    "    \n",
    "    numerator = preds * ground_truth\n",
    "    numerator = torch.sum(numerator, dim=dim)\n",
    "\n",
    "    p_squared = torch.square(preds)\n",
    "    p_squared = torch.sum(p_squared, dim=dim)\n",
    "    # ground_truth is not squared to avoid unnecessary computation.\n",
    "    # 0^2 = 0\n",
    "    # 1^2 = 1\n",
    "    g_squared = torch.sum(torch.square(ground_truth), dim=dim)\n",
    "    denominator = p_squared + g_squared + eps\n",
    "\n",
    "    dice = 2 * numerator / denominator\n",
    "    return 1 - dice\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        if getattr(m, 'bias') is not None:\n",
    "            m.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "class NnModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self, model, loss,\n",
    "            T_0=10, T_mult=2, experiment=None, enable_image_logging=True,\n",
    "            cut_window=(8, 8), lr=1e-3, lr_list=None, epoch_list=None):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.cut_window = cut_window\n",
    "        self.lr = lr\n",
    "        self.experiment = experiment\n",
    "        self.enable_image_logging = enable_image_logging\n",
    "\n",
    "        if lr_list is not None and epoch_list is not None:\n",
    "            if len(lr_list) != len(epoch_list):\n",
    "                raise ValueError(\n",
    "                    f\"lr_list={lr_list} and epoch_list={epoch_list}\"+\\\n",
    "                    \" must be arrays of same length\"\n",
    "                )\n",
    "            print(\n",
    "                f'Using dynamic lr with next setup: lr_list={lr_list} epoch_list={sorted(epoch_list)}.\\n+'+\\\n",
    "                'Epoch list is sorted by increasing.'\n",
    "            )\n",
    "            # Further lr/epoch value will be added/deleted into list\n",
    "            # So, make copy to make sure that original data is safe\n",
    "            lr_list = copy.deepcopy(lr_list)\n",
    "            epoch_list = copy.deepcopy(epoch_list)\n",
    "\n",
    "            self.lr_list = lr_list\n",
    "            self.epoch_list = sorted(epoch_list)\n",
    "            self.is_lr_must_change = True\n",
    "        else:\n",
    "            self.is_lr_must_change = False\n",
    "\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "    def on_train_epoch_start(self):\n",
    "        if self.is_lr_must_change and len(self.epoch_list) != 0:\n",
    "            # Check, current epoch bigger than epoch on which must be updated lr\n",
    "            if self.current_epoch >= self.epoch_list[0]:\n",
    "                # Update optimizer\n",
    "                self.lr = self.lr_list[0]\n",
    "                self.trainer.accelerator.setup_optimizers(self.trainer)\n",
    "                # Clear used variables\n",
    "                del self.epoch_list[0]\n",
    "                del self.lr_list[0]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Change lr after some epoch\n",
    "        # https://github.com/PyTorchLightning/pytorch-lightning/issues/3095\n",
    "        # In this code I do something different and its more what I like\n",
    "        print(f'Init optimizer with params: lr={self.lr}, T_0={self.T_0}, T_mult={self.T_mult}')\n",
    "        optimizer = optim.Adam( \n",
    "            self.parameters(), lr=self.lr\n",
    "        )\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, \n",
    "            T_0=self.T_0, T_mult=self.T_mult, eta_min=0\n",
    "        )\n",
    "        return { \"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler }\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        img, mask = train_batch\n",
    "        preds = self.model(img) # (N, C, 8, 8)\n",
    "        loss = self.loss(preds, mask) # (N, 8, 8)\n",
    "        self.log('train_loss', loss)\n",
    "        if self.experiment is not None:\n",
    "            self.experiment.log_metric(\"train_loss\", loss, epoch=self.current_epoch, step=self.global_step)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return batch\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        print('Size epoch end input: ', len(outputs))\n",
    "        \n",
    "        pred_tensor, target_tensor = collect_prediction_and_target(outputs, self.model, cut_window=self.cut_window)\n",
    "        target_one_hotted_tensor = torch.nn.functional.one_hot(\n",
    "            target_tensor, 17 # Num classes\n",
    "        )\n",
    "        # (N, H, W, C) --> (N, C, H, W)\n",
    "        target_one_hotted_tensor = target_one_hotted_tensor.permute(0, -1, 1, 2)\n",
    "        dice_loss_val = dice_loss(pred_tensor, target_one_hotted_tensor, dim=[0, 2, 3], use_softmax=True, softmax_dim=1)\n",
    "        metric, pred_as_mask_list = calculate_iou(pred_tensor, target_tensor)\n",
    "        \n",
    "        for batch_idx, (metric_s, target_s, pred_s) in enumerate(zip(metric, target_tensor, pred_as_mask_list)):\n",
    "            if self.enable_image_logging:\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "                sns.heatmap(pred_s.cpu().detach().numpy(), ax=ax1, vmin=0, vmax=17)\n",
    "                sns.heatmap(target_s.cpu().detach().numpy(), ax=ax2, vmin=0, vmax=17)\n",
    "                fig.savefig(f'temp_fig_{GPU_ID}.png')\n",
    "                plt.close(fig)\n",
    "\n",
    "                if self.experiment is not None:\n",
    "                    # For Comet logger\n",
    "                    self.experiment.log_image(\n",
    "                        f'temp_fig_{GPU_ID}.png', name=f'{batch_idx}', \n",
    "                        overwrite=False, step=self.global_step\n",
    "                    )\n",
    "            \n",
    "            d = {f'iou_{i}': iou for i, iou in enumerate(metric_s)}\n",
    "            \n",
    "            if self.experiment is not None:\n",
    "                self.experiment.log_metrics(d, epoch=self.current_epoch)\n",
    "            else:\n",
    "                print(d)\n",
    "        if self.experiment is not None:\n",
    "            # Add confuse matrix\n",
    "            self.experiment.log_confusion_matrix(\n",
    "                target_tensor.cpu().detach().numpy().reshape(-1), \n",
    "                torch.stack(\n",
    "                    [elem.cpu() for elem in pred_as_mask_list], \n",
    "                    dim=0\n",
    "                ).cpu().detach().numpy().reshape(-1)\n",
    "            )\n",
    "            \n",
    "        mean_per_class_metric, mean_metric = clear_metric_calculation(\n",
    "            metric, target_tensor, pred_as_mask_list\n",
    "        )\n",
    "        mean_dice_loss_per_class_dict = {\n",
    "            f\"mean_dice_loss_per_class_{i}\": d_l.float()\n",
    "            for i, d_l in enumerate(dice_loss_val)\n",
    "        }\n",
    "        mean_dice_loss_dict = {\n",
    "            f\"mean_dice_loss\": dice_loss_val.mean().float()\n",
    "        }\n",
    "        mean_iou_class_dict = {\n",
    "            f\"mean_iou_class_{i}\": torch.tensor(iou, dtype=torch.float)\n",
    "            for i, iou in enumerate(mean_per_class_metric)\n",
    "        }\n",
    "        mean_iou_dict = {\n",
    "            \"mean_iou\": torch.tensor(mean_metric, dtype=torch.float),\n",
    "        }\n",
    "        \n",
    "        # Log this metric in order to save checkpoint of experements\n",
    "        self.log_dict(mean_iou_dict)\n",
    "        \n",
    "        if self.experiment is not None:\n",
    "        \n",
    "            self.experiment.log_metrics(\n",
    "                mean_dice_loss_per_class_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "\n",
    "            self.experiment.log_metrics(\n",
    "                mean_dice_loss_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "\n",
    "            self.experiment.log_metrics(\n",
    "                mean_iou_class_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "\n",
    "            self.experiment.log_metrics(\n",
    "                mean_iou_dict,\n",
    "                epoch=self.current_epoch\n",
    "            )\n",
    "        else:\n",
    "            print(mean_dice_loss_per_class_dict)\n",
    "            print(mean_dice_loss_dict)\n",
    "            print(mean_iou_class_dict)\n",
    "            print(mean_iou_dict)\n",
    "            print('---------------------------------')\n",
    "\n",
    "\n",
    "device = 'cuda:0'\n",
    "pca_explained_variance = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaExplainedVariance_.npy')\n",
    "pca_mean = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaMean.npy')\n",
    "pca_components = np.load(f'{PREFIX_INFO_PATH}/kfold0_PcaComponents.npy')\n",
    "\n",
    "\n",
    "def pca_transformation(x):\n",
    "    if len(x.shape) == 3:\n",
    "        x_t = x.reshape((x.shape[0], -1)) # (C, H, W) -> (C, H * W)\n",
    "        x_t = np.transpose(x_t, (1, 0)) # (C, H * W) -> (H * W, C)\n",
    "        x_t = x_t - pca_mean\n",
    "        x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "        return x_t.reshape((x.shape[1], x.shape[2], pca_components.shape[0])).astype(np.float32, copy=False) # (H, W, N)\n",
    "    elif len(x.shape) == 4:\n",
    "        # x - (N, C, H, W)\n",
    "        x_t = np.transpose(x, (0, 2, 3, 1)) # (N, C, H, W) -> (N, H, W, C)\n",
    "        x_t = x_t - pca_mean\n",
    "        x_t = np.dot(x_t, pca_components.T) / np.sqrt(pca_explained_variance)\n",
    "        x_t = np.transpose(x_t, (0, -1, 1, 2)) # (N, H, W, C) -> (N, C, H, W)\n",
    "        return x_t.astype(np.float32, copy=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown shape={x.shape}, must be of len 3 or 4.\")\n",
    "\n",
    "def standartization(img, mean, std):\n",
    "    img -= mean\n",
    "    img /= std\n",
    "    return img\n",
    "\n",
    "def standartization_pool(mean, std):\n",
    "    # X shape - (N, C, H, W)\n",
    "    # from shape (comp,) -> (1, comp, 1, 1)\n",
    "    mean = np.expand_dims(np.expand_dims(np.array(mean, dtype=np.float32), axis=-1), axis=-1)\n",
    "    std = np.expand_dims(np.expand_dims(np.array(std, dtype=np.float32), axis=-1), axis=-1)\n",
    "    \n",
    "    return lambda x: standartization(x, mean=mean, std=std)\n",
    "\n",
    "\n",
    "@nb.njit\n",
    "def mask2class_np(mask_np):\n",
    "    new_class_np = np.zeros((len(mask_np), 1), dtype=mask_np.dtype)\n",
    "    for m_i in range(len(mask_np)):\n",
    "        single_mask = mask_np[m_i]\n",
    "        # (1, h, w)\n",
    "        shape = single_mask.shape\n",
    "        shift_w, shift_h = (shape[2]-1)//2, (shape[1]-1)//2\n",
    "\n",
    "        new_class_np[m_i] = single_mask[0, shift_h, shift_w]\n",
    "    return new_class_np\n",
    "\n",
    "\n",
    "def mask2class_single(mask):\n",
    "    # (1, h, w)\n",
    "    shape = mask.shape\n",
    "    shift_w, shift_h = (shape[2]-1)//2, (shape[1]-1)//2\n",
    "    return mask[0:1, shift_h, shift_w]\n",
    "\n",
    "\n",
    "with open(f'{PREFIX_INFO_PATH}/data_standartization_params_kfold0.json', 'r') as f:\n",
    "    data_standartization_params = json.load(f)\n",
    "MEAN = data_standartization_params.get('means')\n",
    "STD = data_standartization_params.get('stds')\n",
    "\n",
    "MEAN_EXPAND = np.expand_dims(np.expand_dims(MEAN, axis=-1), axis=-1)\n",
    "STD_EXPAND = np.expand_dims(np.expand_dims(STD, axis=-1), axis=-1)\n",
    "\n",
    "\n",
    "def preprocessing(imgs, masks, map_mask_to_class=False):\n",
    "    imgs_np = np.asarray(imgs, dtype=np.float32) # (N, 237, 1, 1)\n",
    "    masks_np = np.asarray(masks, dtype=np.int64) # (N, 1, 1, 3)\n",
    "    # Wo PCA\n",
    "    # _images = [np.transpose(image, (1, 2, 0)) for image in imgs]\n",
    "    # W Pca\n",
    "    _images = pca_transformation(imgs_np)\n",
    "    _images = standartization(_images, MEAN_EXPAND, STD_EXPAND)\n",
    "    _masks = np.transpose(masks_np[..., 0:1], (0, -1, 1, 2))\n",
    "    if map_mask_to_class:\n",
    "        _masks = mask2class_np(_masks)\n",
    "    return _images, _masks\n",
    "\n",
    "\n",
    "def test_augmentation(image, mask, map_mask_to_class=False, **kwargs):\n",
    "    image = torch.from_numpy(image)\n",
    "    image = image.float()\n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    \n",
    "    mask = torch.from_numpy(mask)\n",
    "    mask = mask.long()\n",
    "    mask = torch.squeeze(mask, 0)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "\n",
    "def aug_random_rotate(image, mask, map_mask_to_class=False, **kwargs):\n",
    "    angle = T.RandomRotation.get_params((-30, 30))\n",
    "    image = TF.rotate(image, angle, interpolation=T.InterpolationMode.BILINEAR)\n",
    "    if not map_mask_to_class:\n",
    "        mask = TF.rotate(mask, angle, interpolation=T.InterpolationMode.NEAREST)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def aug_flip_horizontal(image, mask, map_mask_to_class=False, **kwargs):\n",
    "    if torch.rand(1) > 0.5:\n",
    "        image = TF.hflip(image)\n",
    "        if not map_mask_to_class:\n",
    "            mask = TF.hflip(mask)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def aug_flip_vertical(image, mask, map_mask_to_class=False, **kwargs):\n",
    "    if torch.rand(1) > 0.5:\n",
    "        image = TF.vflip(image)\n",
    "        if not map_mask_to_class:\n",
    "            mask = TF.vflip(mask)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "MASK_AUG_SCALE = 100\n",
    "MASK_AUG_COMPARE = 90\n",
    "RandomEraseTorch = T.RandomErasing(\n",
    "    p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), \n",
    "    value='random', inplace=False\n",
    ")\n",
    "def aug_random_erase(image, mask, map_mask_to_class=False, **kwargs):\n",
    "    # Create mask in order to take area of aug\n",
    "    mask_aug_area = torch.ones(\n",
    "        1, image.shape[1], image.shape[2], \n",
    "        dtype=image.dtype, device=image.device\n",
    "    ) * MASK_AUG_SCALE\n",
    "    in_x = torch.cat([image, mask_aug_area], dim=0)\n",
    "    # Apply aug\n",
    "    img_aug = RandomEraseTorch(in_x)\n",
    "    image = img_aug[:-1]\n",
    "    if not map_mask_to_class:\n",
    "        mask_aug = img_aug[-1:]\n",
    "        # Take mask and reverse values\n",
    "        # 0 - cutout zone, 1 - good zone\n",
    "        mask_aug = (mask_aug > MASK_AUG_COMPARE).long()\n",
    "        mask = mask * mask_aug\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "AUGS_LIST = [\n",
    "    aug_random_rotate,\n",
    "    aug_flip_horizontal,\n",
    "    aug_flip_vertical,\n",
    "#    aug_random_erase\n",
    "]\n",
    "\n",
    "\n",
    "def augmentation(image, mask, map_mask_to_class=False, ignore_image_augs=False):\n",
    "    image = torch.from_numpy(image)\n",
    "    image = image.float()\n",
    "    mask = torch.from_numpy(mask)\n",
    "    mask = mask.long()\n",
    "\n",
    "    if not ignore_image_augs:\n",
    "        for aug_func in AUGS_LIST:\n",
    "            image, mask = aug_func(image, mask, map_mask_to_class=map_mask_to_class)\n",
    "    \n",
    "    #image = (image - image.min()) / (image.max() - image.min())\n",
    "    mask = torch.squeeze(mask, -1)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "class MySuperNetLittleInput(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_f=237, out_f=17, cut_window=(8, 8), *args):\n",
    "        super().__init__()\n",
    "        #self.bn_start = nn.BatchNorm3d(in_f)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_f, 128, kernel_size=3, stride=1, padding=1)\n",
    "        # (N, 128, 8, 8)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.act1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        # (N, 128, 8, 8)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.act2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        # (N, 64, 8, 8)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.act3 = nn.ReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        # (N, 64, 8, 8)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        final_h, final_w = cut_window[0], cut_window[1]\n",
    "        self.f1 = nn.Linear(64 * final_h * final_w, 256, bias=False)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.f2 = nn.Linear(256, out_f, bias=False)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.act3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.act4(x)\n",
    "\n",
    "        x = torch.flatten(x, 1) # aka (N, -1)\n",
    "        x = self.f1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.f2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f19ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_test.npy')\n",
    "train_indices = np.load(f'{PREFIX_INFO_PATH}/kfold0_indx_train.npy')\n",
    "cut_window=(3,3)\n",
    "batch_size=1_000\n",
    "NUM_WORKERS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5de484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "# Train\n",
    "dataset_creator_train = DatasetCreator(\n",
    "    PATH_DATA, \n",
    "    indices=train_indices, cut_window=cut_window,\n",
    "    shuffle_then_prepared=True,\n",
    "    map_mask_to_class=True\n",
    ")\n",
    "dataset_train = HsiDataloaderCutter(\n",
    "    images=dataset_creator_train.images, masks=dataset_creator_train.masks,\n",
    "    augmentation=augmentation,\n",
    "    preprocessing=preprocessing,\n",
    "    shuffle_data=True, cut_window=cut_window,\n",
    "    map_mask_to_class=True,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "print(f\"Number of workers={NUM_WORKERS}\")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=None, \n",
    "    num_workers=NUM_WORKERS, pin_memory=False,\n",
    ")\n",
    "# Test\n",
    "dataset_creator_test = DatasetCreator(\n",
    "    PATH_DATA,\n",
    "    indices=test_indices, cut_window=None,\n",
    "    map_mask_to_class=False\n",
    ")\n",
    "dataset_test = HsiDataloaderCutter(\n",
    "    images=dataset_creator_test.images, masks=dataset_creator_test.masks,\n",
    "    augmentation=test_augmentation,\n",
    "    preprocessing=preprocessing,\n",
    "    shuffle_data=False, cut_window=None,\n",
    "    map_mask_to_class=False,\n",
    "    batch_size=1\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e6fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for in_data_x, val_data in test_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data_x.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_creator_test.masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff1dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mean.shape, pca_components.shape, pca_explained_variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5285802",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(17, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f058e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr -= pca_explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!df -h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14eee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
